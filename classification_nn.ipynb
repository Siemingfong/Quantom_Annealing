{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) 2019 Willy Po-Wei Wu <maya6282@gmail.com> and Elvis Yu-Jing Lin <elvisyjlin@gmail.com>\n",
    "\n",
    "This work is licensed under the Creative Commons Attribution-NonCommercial\n",
    "4.0 International License. To view a copy of this license, visit\n",
    "http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n",
    "Creative Commons, PO Box 1866, Mountain View, CA 94042, USA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Abbreviations\n",
    "1. cm: confusion matrix\n",
    "2. rp: classification report\n",
    "3. fi: feature importance\n",
    "4. if: important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all used packages\n",
    "\n",
    "import argparse\n",
    "import collections\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from learn import get_model, get_params\n",
    "from utils import run_from_ipython, np2df\n",
    "from viz import show_cm_list, show_rp_list\n",
    "\n",
    "if run_from_ipython():\n",
    "    import matplotlib\n",
    "    %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    sns.set_context('notebook')  # 'notebook', 'paper', 'talk', 'poster'\n",
    "    # sns.set_style('dark')  # None, 'darkgrid', 'whitegrid', 'dark', 'white', 'ticks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(feature_type='bem', gpu=False, n_folds=10, output='./data_p', result='./result', scheme='address', temp='./temp')\n"
     ]
    }
   ],
   "source": [
    "# Parse Arguments\n",
    "\n",
    "def parse(args=None):\n",
    "    parser = argparse.ArgumentParser(\n",
    "        prog='Classification',\n",
    "        description='Train and test a machine learning classification method on the extracted features.'\n",
    "    )\n",
    "    parser.add_argument('--n_folds', help='n folds cross validation', type=int, default=10)\n",
    "    parser.add_argument('--feature_type', '-f',\n",
    "                        help='feature type (\"b\" | \"e\" | \"m\" or \"if4\", \"if5\", \"if10\", \"if13\", \"if20\", \"if64\")',\n",
    "                        type=str, default='bem')\n",
    "    parser.add_argument('--scheme', '-s', help='data scheme', type=str,\n",
    "                        choices=['address', 'entity'], default='address')\n",
    "    parser.add_argument('--gpu', help='use GPU', action='store_true')\n",
    "    parser.add_argument('--output', '-o', help='output path', type=str, default='./data_p')\n",
    "    parser.add_argument('--result', '-r', help='result path', type=str, default='./result')\n",
    "    parser.add_argument('--temp', '-t', help='temp path', type=str, default='./temp')\n",
    "    return parser.parse_args() if args is None else parser.parse_args(args)\n",
    "args = parse([]) if run_from_ipython() else parse()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Setting\n",
      "===> Feature Types:   bem\n",
      "===> Data Scheme:     address\n",
      "===> Use GPU:         False\n",
      "===> Training epochs: 4000\n"
     ]
    }
   ],
   "source": [
    "# Define the experiment setting\n",
    "\n",
    "n_folds = args.n_folds                       # 10\n",
    "feature_type = args.feature_type             # 'b' | 'e' | 'm' or 'if4', 'if5', 'if10', 'if13', 'if20', 'if64'\n",
    "scheme = args.scheme                         # 'address', 'entity'\n",
    "gpu = args.gpu\n",
    "output_path = args.output\n",
    "result_path = args.result\n",
    "temp_path = args.temp\n",
    "\n",
    "# Check the experiment setting\n",
    "\n",
    "assert not feature_type.startswith('if') and len(feature_type) > 0 or \\\n",
    "       feature_type.startswith('if') and feature_type[2:].isdigit()\n",
    "assert scheme in ['address', 'entity']\n",
    "\n",
    "# Number of epochs to train\n",
    "# The specified epochs are enough to converge for each scheme\n",
    "if scheme == 'address':\n",
    "    epochs = 4000\n",
    "elif scheme == 'entity':\n",
    "    epochs = 1500\n",
    "\n",
    "# Show the experiment setting\n",
    "\n",
    "print('Experiment Setting')\n",
    "print('===> Feature Types:  ', feature_type)\n",
    "print('===> Data Scheme:    ', scheme)\n",
    "print('===> Use GPU:        ', gpu)\n",
    "print('===> Training epochs:', epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義一個函數來加載和抽樣數據\n",
    "def load_sample(file_path, sample_fraction=0.1):\n",
    "    chunks = []\n",
    "    for chunk in pd.read_csv(file_path, chunksize=100000):\n",
    "        chunks.append(chunk.sample(frac=sample_fraction))\n",
    "    return pd.concat(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             n_tx  total_days  total_spent_btc  total_received_btc  \\\n",
      "69550   -0.101101   -0.269812        -0.021248           -0.021248   \n",
      "18265    0.853478    1.912386        -0.007867           -0.007867   \n",
      "78135   -0.101101   -0.391565        -0.019181           -0.019181   \n",
      "65117   -0.180649   -0.400931         0.005184            0.005184   \n",
      "49077   -0.101101    0.891529        -0.019657           -0.019657   \n",
      "...           ...         ...              ...                 ...   \n",
      "1833867  0.933027   -0.400931         0.001650            0.001650   \n",
      "1810187 -0.180649   -0.400931        -0.015523           -0.015523   \n",
      "1849393 -0.180649   -0.400931        -0.010450           -0.010450   \n",
      "1855868  0.296641   -0.400931        -0.016439           -0.016439   \n",
      "1829985 -0.180649   -0.400931        -0.020886           -0.020886   \n",
      "\n",
      "         total_spent_usd  total_received_usd  mean_balance_btc  \\\n",
      "69550          -0.013996           -0.013996         -0.130665   \n",
      "18265          -0.012900           -0.012900         -0.099771   \n",
      "78135          -0.008678           -0.008678         -0.094980   \n",
      "65117           0.017056            0.017056          0.784200   \n",
      "49077          -0.013121           -0.013121         -0.103206   \n",
      "...                  ...                 ...               ...   \n",
      "1833867        -0.011864           -0.011864         -0.080093   \n",
      "1810187        -0.008637           -0.008637          0.069417   \n",
      "1849393        -0.013076           -0.013076          0.244530   \n",
      "1855868        -0.013578           -0.013578         -0.108698   \n",
      "1829985        -0.013005           -0.013005         -0.115712   \n",
      "\n",
      "         std_balance_btc  mean_balance_usd  std_balance_usd  ...  \\\n",
      "69550          -0.002451         -0.060000        -0.002643  ...   \n",
      "18265          -0.002434         -0.060134        -0.002643  ...   \n",
      "78135          -0.002448          0.011076        -0.002623  ...   \n",
      "65117          -0.002451          0.772511        -0.002643  ...   \n",
      "49077          -0.002450         -0.048299        -0.002643  ...   \n",
      "...                  ...               ...              ...  ...   \n",
      "1833867        -0.002423         -0.058453        -0.002643  ...   \n",
      "1810187        -0.002451          0.085835        -0.002643  ...   \n",
      "1849393        -0.002451         -0.032803        -0.002643  ...   \n",
      "1855868        -0.002448         -0.060260        -0.002643  ...   \n",
      "1829985        -0.002451         -0.030901        -0.002643  ...   \n",
      "\n",
      "         dist_payback_1st_moment  dist_payback_2nd_moment  \\\n",
      "69550                  -0.227282                -0.166689   \n",
      "18265                   0.121018                 0.183258   \n",
      "78135                  -0.374356                -0.172996   \n",
      "65117                  -0.389038                -0.173049   \n",
      "49077                   0.983976                 0.285210   \n",
      "...                          ...                      ...   \n",
      "1833867                -0.376456                -0.173028   \n",
      "1810187                -0.389038                -0.173049   \n",
      "1849393                -0.389038                -0.173049   \n",
      "1855868                -0.388003                -0.173049   \n",
      "1829985                -0.389038                -0.173049   \n",
      "\n",
      "         dist_payback_3rd_moment  dist_payback_4th_moment  tx_input  \\\n",
      "69550                  -0.132643                 0.139411  1.200044   \n",
      "18265                   6.893759                 7.243669 -0.151659   \n",
      "78135                  -0.132643                 0.139411 -0.151659   \n",
      "65117                  -0.132643                -0.518267 -0.039017   \n",
      "49077                  -0.132643                 0.139411 -0.039017   \n",
      "...                          ...                      ...       ...   \n",
      "1833867                -0.491154                 0.344538 -0.151659   \n",
      "1810187                -0.132643                -0.518267  0.298909   \n",
      "1849393                -0.132643                -0.518267 -0.151659   \n",
      "1855868                -1.777514                 0.632670 -0.151659   \n",
      "1829985                -0.132643                -0.518267 -0.151659   \n",
      "\n",
      "         tx_output  n_multi_in  n_multi_out  n_multi_in_out  class  \n",
      "69550     0.108768    1.083671     0.106439        1.520518      0  \n",
      "18265    -0.055827   -0.219166    -0.050256       -0.657671      0  \n",
      "78135    -0.055827   -0.219166    -0.050256       -0.657671      0  \n",
      "65117     0.108768   -0.018729     0.106439        1.520518      0  \n",
      "49077    -0.055827   -0.018729    -0.050256        1.520518      0  \n",
      "...            ...         ...          ...             ...    ...  \n",
      "1833867  -0.138124   -0.018729    -0.050256        1.520518      4  \n",
      "1810187   0.437957    0.281925     0.419830        1.520518      0  \n",
      "1849393  -0.138124   -0.219166    -0.206951       -0.657671      4  \n",
      "1855868  -0.055827   -0.018729    -0.050256        1.520518      4  \n",
      "1829985   0.026471   -0.219166     0.028092       -0.657671      0  \n",
      "\n",
      "[74281 rows x 74 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load transaction history summarization data\n",
    "\n",
    "# 設定樣本比例\n",
    "sample_fraction = 0.04  # 取 0.4% 的數據樣本\n",
    "\n",
    "# data_file = 'data.{}.csv'.format(scheme)\n",
    "data_file = 'nanzero_normalization_data.{}.csv'.format(scheme)\n",
    "# data_file = 'quantum_qubo_data.{}.csv'.format(scheme)\n",
    "# data_file = 'all_selected_features_quantum_qubo_data.{}.csv'.format(scheme)\n",
    "file_path = os.path.join(output_path, data_file)\n",
    "data = load_sample(file_path, sample_fraction)\n",
    "# data = pd.read_csv(os.path.join(output_path, data_file))\n",
    "print (data)\n",
    "if run_from_ipython():\n",
    "    data.head(4)\n",
    "else:\n",
    "    print(data.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f_tx', 'f_received', 'f_coinbase', 'f_spent_digits_-3', 'f_spent_digits_-2', 'f_spent_digits_-1', 'f_spent_digits_0', 'f_spent_digits_1', 'f_spent_digits_2', 'f_spent_digits_3', 'f_spent_digits_4', 'f_spent_digits_5', 'f_spent_digits_6', 'f_received_digits_-3', 'f_received_digits_-2', 'f_received_digits_-1', 'f_received_digits_0', 'f_received_digits_1', 'f_received_digits_2', 'f_received_digits_3', 'f_received_digits_4', 'f_received_digits_5', 'f_received_digits_6', 'r_payback', 'n_inputs_in_spent', 'n_outputs_in_spent', 'n_tx', 'total_days', 'n_spent', 'n_received', 'n_coinbase', 'n_payback', 'total_spent_btc', 'total_received_btc', 'total_spent_usd', 'total_received_usd', 'mean_balance_btc', 'std_balance_btc', 'mean_balance_usd', 'std_balance_usd', 'interval_1st_moment', 'interval_2nd_moment', 'interval_3rd_moment', 'interval_4th_moment', 'dist_total_1st_moment', 'dist_total_2nd_moment', 'dist_total_3rd_moment', 'dist_total_4th_moment', 'dist_coinbase_1st_moment', 'dist_coinbase_2nd_moment', 'dist_coinbase_3rd_moment', 'dist_coinbase_4th_moment', 'dist_spend_1st_moment', 'dist_spend_2nd_moment', 'dist_spend_3rd_moment', 'dist_spend_4th_moment', 'dist_receive_1st_moment', 'dist_receive_2nd_moment', 'dist_receive_3rd_moment', 'dist_receive_4th_moment', 'dist_payback_1st_moment', 'dist_payback_2nd_moment', 'dist_payback_3rd_moment', 'dist_payback_4th_moment']\n",
      "bem\n",
      "[[-4.26106082e-01  3.06579805e-03 -3.06579805e-03 ... -1.66688550e-01\n",
      "  -1.32642675e-01  1.39411131e-01]\n",
      " [-4.73898707e-01  3.06579805e-03 -3.06579805e-03 ...  1.83258297e-01\n",
      "   6.89375921e+00  7.24366925e+00]\n",
      " [ 1.12647151e-01  3.06579805e-03 -3.06579805e-03 ... -1.72996483e-01\n",
      "  -1.32642675e-01  1.39411131e-01]\n",
      " ...\n",
      " [ 1.12647151e-01  3.06579805e-03 -3.06579805e-03 ... -1.73048880e-01\n",
      "  -1.32642675e-01 -5.18267307e-01]\n",
      " [ 3.84247722e+00  3.06579805e-03 -3.06579805e-03 ... -1.73048768e-01\n",
      "  -1.77751428e+00  6.32669959e-01]\n",
      " [ 1.12647151e-01  3.06579805e-03 -3.06579805e-03 ... -1.73048880e-01\n",
      "  -1.32642675e-01 -5.18267307e-01]]\n",
      "[0 0 0 ... 4 4 0]\n",
      "['Exchange' 'Faucet' 'Gambling' 'Market' 'Mixer' 'Pool']\n",
      "74281 74281 64\n"
     ]
    }
   ],
   "source": [
    "# Define 4 types of features (basic statistics, extra statistics, moments and patterns)\n",
    "\n",
    "basic = [\n",
    "    'f_tx', 'f_received', 'f_coinbase',\n",
    "    'f_spent_digits_-3', 'f_spent_digits_-2', 'f_spent_digits_-1', 'f_spent_digits_0',\n",
    "    'f_spent_digits_1', 'f_spent_digits_2', 'f_spent_digits_3', 'f_spent_digits_4',\n",
    "    'f_spent_digits_5', 'f_spent_digits_6', 'f_received_digits_-3', 'f_received_digits_-2',\n",
    "    'f_received_digits_-1', 'f_received_digits_0', 'f_received_digits_1', 'f_received_digits_2',\n",
    "    'f_received_digits_3', 'f_received_digits_4', 'f_received_digits_5', 'f_received_digits_6',\n",
    "    'r_payback', 'n_inputs_in_spent', 'n_outputs_in_spent'\n",
    "]\n",
    "extra = [\n",
    "    'n_tx', 'total_days', 'n_spent', 'n_received', 'n_coinbase', 'n_payback',\n",
    "    'total_spent_btc', 'total_received_btc',\n",
    "    'total_spent_usd', 'total_received_usd',\n",
    "    'mean_balance_btc', 'std_balance_btc',\n",
    "    'mean_balance_usd', 'std_balance_usd'\n",
    "]\n",
    "moments = [\n",
    "    'interval_1st_moment', 'interval_2nd_moment', 'interval_3rd_moment', 'interval_4th_moment',\n",
    "    'dist_total_1st_moment', 'dist_total_2nd_moment', 'dist_total_3rd_moment', 'dist_total_4th_moment',\n",
    "    'dist_coinbase_1st_moment', 'dist_coinbase_2nd_moment', 'dist_coinbase_3rd_moment', 'dist_coinbase_4th_moment',\n",
    "    'dist_spend_1st_moment', 'dist_spend_2nd_moment', 'dist_spend_3rd_moment', 'dist_spend_4th_moment',\n",
    "    'dist_receive_1st_moment', 'dist_receive_2nd_moment', 'dist_receive_3rd_moment', 'dist_receive_4th_moment',\n",
    "    'dist_payback_1st_moment', 'dist_payback_2nd_moment', 'dist_payback_3rd_moment', 'dist_payback_4th_moment'\n",
    "]\n",
    "patterns =[\n",
    "    'tx_input', 'tx_output',\n",
    "    'n_multi_in', 'n_multi_out', 'n_multi_in_out'\n",
    "]\n",
    "\n",
    "features = []\n",
    "if not feature_type.startswith('if') and len(feature_type) > 0:\n",
    "    if 'b' in feature_type:\n",
    "        features += basic\n",
    "    if 'e' in feature_type:\n",
    "        features += extra\n",
    "    if 'm' in feature_type:\n",
    "        features += moments\n",
    "    if 'p' in feature_type:\n",
    "        features += patterns\n",
    "        print(\"Patterns included:\", patterns)\n",
    "elif feature_type.startswith('if') and feature_type[2:].isdigit():\n",
    "    \"\"\"\n",
    "    Important features from LightGBM with BEM\n",
    "    [ 0 25 24 29 40 37 27 23 56 36  1 28 26 57 32 38 44 45 33 18 39 60 53 35\n",
    "     34 52 41 17 14 15 16 19 42  5  6 47  7 46  2 54  4 43  8 59 58 55  9 13\n",
    "     61 48  3 31 10 62 20 21 63 30 49 11 51 50 22 12]\n",
    "    \"\"\"\n",
    "    all_features = basic + extra + moments + patterns\n",
    "    if_indices = [\n",
    "        0, 25, 24, 29, 40, 37, 27, 23, 56, 36,\n",
    "        1, 28, 26, 57, 32, 38, 44, 45, 33, 18,\n",
    "        39, 60, 53, 35, 34, 52, 41, 17, 14, 15,\n",
    "        16, 19, 42, 5, 6, 47, 7, 46, 2, 54,\n",
    "        4, 43, 8, 59, 58, 55, 9, 13, 61, 48,\n",
    "        3, 31, 10, 62, 20, 21, 63, 30, 49, 11,\n",
    "        51, 50, 22, 12\n",
    "    ]\n",
    "    if_features = [all_features[i] for i in if_indices]\n",
    "    n_if = int(feature_type[2:])\n",
    "    features = if_features[:n_if]\n",
    "else:\n",
    "    raise Exception('Invalid feature types: {:s}'.format(feature_type))\n",
    "\n",
    "invalid_features = [feature for feature in features if feature not in data.columns]\n",
    "assert len(invalid_features) == 0, 'Invalid features: ' + ', '.join(invalid_features)\n",
    "\n",
    "X = data.get(features).values\n",
    "y = data['class'].values\n",
    "print (features)\n",
    "print (feature_type)\n",
    "print (X)\n",
    "print (y)\n",
    "\n",
    "class2label = json.loads(open(os.path.join(output_path, 'class2label.json'), 'r').read())\n",
    "label2class = json.loads(open(os.path.join(output_path, 'label2class.json'), 'r').read())\n",
    "class_names = np.array([label2class[i] for i in range(6)])\n",
    "print (class_names)\n",
    "y_names = class_names\n",
    "# y_names = class_names[y]\n",
    "# y_names = np.array(class_names)[y.astype(int)]\n",
    "\n",
    "print(len(X), len(y), len(features))\n",
    "\n",
    "os.makedirs(result_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_distribution(df):\n",
    "#     if run_from_ipython():\n",
    "#         plt.figure()\n",
    "#         sns.countplot(df.index)\n",
    "#     cnt = collections.Counter(df.index)\n",
    "#     print(cnt)\n",
    "#     return np.array([cnt[i] for i in range(len(cnt))])\n",
    "\n",
    "# print(class2label)\n",
    "# y_count = data_distribution(np2df(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import BatchNormalization, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "\n",
    "# 如果不想使用 GPU，可以設置環境變量\n",
    "if not gpu:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# GPU 配置 for TensorFlow 2.x\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # 為每個 GPU 設置允許記憶體增長\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "def build_model(input_size, num_classes, summary=False):\n",
    "    model = Sequential([\n",
    "        Dense(512, activation='relu', input_shape=(input_size,)),\n",
    "        BatchNormalization(momentum=0.0, epsilon=1e-5),\n",
    "        Dropout(0.2),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(momentum=0.0, epsilon=1e-5),\n",
    "        Dropout(0.2),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(momentum=0.0, epsilon=1e-5),\n",
    "        Dropout(0.2),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(momentum=0.0, epsilon=1e-5),\n",
    "        Dropout(0.2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    if summary:\n",
    "        model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               33280     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 512)               2048      \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 512)               2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6)                 3078      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 832518 (3.18 MB)\n",
      "Trainable params: 828422 (3.16 MB)\n",
      "Non-trainable params: 4096 (16.00 KB)\n",
      "_________________________________________________________________\n",
      "0.2641001343727112 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SIEMINGFONG\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3673442006111145 1\n",
      "0.4078610837459564 2\n",
      "0.440839946269989 3\n",
      "0.4486472010612488 4\n",
      "0.4510701298713684 6\n",
      "0.46506932377815247 7\n",
      "0.4674922525882721 8\n",
      "0.4711266756057739 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:28, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m---> 44\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     accs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtest_on_batch(X_valid, y_valid_)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accs[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m acc:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\src\\engine\\training.py:2684\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   2680\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39msingle_batch_iterator(\n\u001b[0;32m   2681\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, x, y, sample_weight, class_weight\n\u001b[0;32m   2682\u001b[0m     )\n\u001b[0;32m   2683\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[1;32m-> 2684\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2686\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   2687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time  # 加入時間模組\n",
    "\n",
    "# 訓練過程\n",
    "train_cm_list = []\n",
    "train_rp_list = []\n",
    "valid_cm_list = []\n",
    "valid_rp_list = []\n",
    "fi_list = []\n",
    "\n",
    "# Add these lists to store AUC scores\n",
    "train_auc_list = []\n",
    "valid_auc_list = []\n",
    "\n",
    "# 宣告 K-Fold\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "# # 標準化資料\n",
    "# print('Normalizing data...')\n",
    "# X = np.nan_to_num((X - np.mean(X, axis=0)) / np.std(X, axis=0))\n",
    "# X = np.clip(X, np.percentile(X, 1, axis=0), np.percentile(X, 99, axis=0))\n",
    "\n",
    "# 開始計算整體訓練時間\n",
    "total_start_time = time.time()  # 全部訓練開始時間\n",
    "\n",
    "# 開始交叉驗證\n",
    "for i, (train_idx, valid_idx) in tqdm(enumerate(skf.split(X, y))):\n",
    "    # 取得分割的訓練集和驗證集\n",
    "    X_train, X_valid = X[train_idx], X[valid_idx]\n",
    "    y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "    y_train_ = keras.utils.to_categorical(y_train, num_classes=len(class2label))\n",
    "    y_valid_ = keras.utils.to_categorical(y_valid, num_classes=len(class2label))\n",
    "    \n",
    "    # 建立模型\n",
    "    model = build_model(X.shape[1], len(label2class), summary=(i==0))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-4, beta_1=0.5, beta_2=0.999),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # 訓練模型\n",
    "    acc = -1\n",
    "    for epoch in range(epochs):\n",
    "        model.train_on_batch(X_train, y_train_)\n",
    "        accs = model.test_on_batch(X_valid, y_valid_)\n",
    "        if accs[1] > acc:\n",
    "            acc = accs[1]\n",
    "            print(acc, epoch)\n",
    "            model.save(os.path.join(temp_path, 'model.h5'))\n",
    "    model = load_model(os.path.join(temp_path, 'model.h5'))\n",
    "    \n",
    "    # 在訓練集上評估\n",
    "    y_pred = np.argmax(model.predict(X_train), axis=1)\n",
    "    cm = confusion_matrix(y_train, y_pred)\n",
    "    cm_sum = cm.sum(axis=1, keepdims=True)\n",
    "    cm_sum[cm_sum == 0] = 1  # 防止除零\n",
    "    cm = cm / cm_sum\n",
    "    train_cm_list.append(cm)\n",
    "    \n",
    "    # 在驗證集上評估\n",
    "    y_pred = np.argmax(model.predict(X_valid), axis=1)\n",
    "    cm = confusion_matrix(y_valid, y_pred)\n",
    "    cm = cm / cm.sum(axis=1, keepdims=True)\n",
    "    valid_cm_list.append(cm)\n",
    "    rp = classification_report(y_valid, y_pred, target_names=class_names, output_dict=True)\n",
    "    valid_rp_list.append(rp)\n",
    "    \n",
    "\n",
    "# 全部訓練結束時間\n",
    "total_end_time = time.time()\n",
    "total_training_time = total_end_time - total_start_time  # 計算總訓練時間\n",
    "print(f\"Total training time: {total_training_time:.2f} seconds\")  # 輸出總訓練時間\n",
    "\n",
    "# 清除臨時檔案\n",
    "shutil.rmtree(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the result path if it does not exist\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)\n",
    "\n",
    "# Save training results\n",
    "\n",
    "experiment_name = os.path.join(result_path, '{}.{}.{}'.format(model, feature_type, scheme))\n",
    "if not cost_sensitive:\n",
    "    experiment_name += '.no_cs'\n",
    "results = {\n",
    "    'train_cm_list': train_cm_list,\n",
    "    'valid_cm_list': valid_cm_list,\n",
    "    'train_rp_list': train_rp_list,\n",
    "    'valid_rp_list': valid_rp_list,\n",
    "    'fi_list': fi_list,\n",
    "    'train_auc_list': train_auc_list,\n",
    "    'valid_auc_list': valid_auc_list\n",
    "}\n",
    "pickle.dump(results, open(experiment_name + '.pkl', 'wb'))\n",
    "\n",
    "# Save model\n",
    "model_save_path = '{}_model.pkl'.format(experiment_name)\n",
    "with open(model_save_path, 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "print(f\"Results and model saved to {result_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average confusion matrix of training set in K-fold\n",
    "\n",
    "print('Average confusion matrix of training set in {:d}-fold'.format(n_folds))\n",
    "show_cm_list(train_cm_list, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average classification report of training set in K-fold\n",
    "\n",
    "print('Average classification report of training set in {:d}-fold'.format(n_folds))\n",
    "show_rp_list(train_rp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_rp_list_and_accuracies(rp_list, cm_list, class_names):\n",
    "    summed_metrics = {}\n",
    "    summed_accuracy = 0\n",
    "    summed_category_accuracies = {category: 0 for category in class_names}\n",
    "    category_supports = {category: 0 for category in class_names}\n",
    "\n",
    "    for report_index, report in enumerate(rp_list):\n",
    "        for category, metrics in report.items():\n",
    "            if category == 'accuracy':\n",
    "                summed_accuracy += metrics\n",
    "                continue\n",
    "\n",
    "            if isinstance(metrics, dict) and category in class_names:\n",
    "                if category not in summed_metrics:\n",
    "                    summed_metrics[category] = {key: 0 for key in metrics if key != 'support'}\n",
    "                for metric, value in metrics.items():\n",
    "                    if metric != 'support':\n",
    "                        summed_metrics[category][metric] += value\n",
    "                category_supports[category] += metrics.get('support', 0)\n",
    "\n",
    "        cm = cm_list[report_index]\n",
    "        for i, category in enumerate(class_names):\n",
    "            TP = cm[i, i]\n",
    "            TN = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - TP)\n",
    "            FP = cm[:, i].sum() - TP\n",
    "            FN = cm[i, :].sum() - TP\n",
    "            accuracy = (TP + TN) / float(TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
    "            summed_category_accuracies[category] += accuracy\n",
    "\n",
    "    avg_metrics = {}\n",
    "    total_support = sum(category_supports.values())\n",
    "    macro_avg = {'precision': 0, 'recall': 0, 'f1-score': 0}\n",
    "    weighted_avg = {'precision': 0, 'recall': 0, 'f1-score': 0}\n",
    "\n",
    "    for category, metrics in summed_metrics.items():\n",
    "        avg_metrics[category] = {metric: value / len(rp_list) for metric, value in metrics.items()}\n",
    "        for metric in macro_avg:\n",
    "            macro_avg[metric] += avg_metrics[category][metric] / len(class_names)\n",
    "            weighted_avg[metric] += (avg_metrics[category][metric] * category_supports[category]) / total_support\n",
    "\n",
    "    avg_accuracy = summed_accuracy / len(rp_list)\n",
    "    avg_category_accuracies = {category: acc / len(cm_list) for category, acc in summed_category_accuracies.items()}\n",
    "\n",
    "    print(f\"Overall Accuracy: {avg_accuracy}\\n\")\n",
    "    for category, metrics in avg_metrics.items():\n",
    "        print(f\"Category: {category}\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"  {metric}: {value}\")\n",
    "        print(f\"  Accuracy: {avg_category_accuracies[category]}\\n\")\n",
    "\n",
    "    print(\"Category: macro avg\")\n",
    "    for metric, value in macro_avg.items():\n",
    "        print(f\"  {metric}: {value}\")\n",
    "    print(\"\\nCategory: weighted avg\")\n",
    "    for metric, value in weighted_avg.items():\n",
    "        print(f\"  {metric}: {value}\")\n",
    "\n",
    "# Assuming n_folds, train_rp_list, train_cm_list, and class_names are defined elsewhere\n",
    "print('Average classification report and accuracies of training set in {:d}-fold'.format(n_folds))\n",
    "show_rp_list_and_accuracies(train_rp_list, train_cm_list, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average confusion matrix of validataion set in K-fold\n",
    "\n",
    "print('Average confusion matrix of validataion set in {:d}-fold'.format(n_folds))\n",
    "show_cm_list(valid_cm_list, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_rp_list_and_accuracies(rp_list, cm_list, class_names):\n",
    "    class_names_list = list(class_names)  # Convert class_names to a list for index access\n",
    "    summed_metrics, avg_metrics = {}, {}\n",
    "    summed_category_accuracies = {category: 0 for category in class_names}\n",
    "    summed_accuracy = 0\n",
    "\n",
    "    for report in rp_list:\n",
    "        for category, metrics in report.items():\n",
    "            if category == 'accuracy':\n",
    "                summed_accuracy += metrics\n",
    "                continue\n",
    "\n",
    "            if category in class_names_list and isinstance(metrics, dict):\n",
    "                if category not in summed_metrics:\n",
    "                    summed_metrics[category] = {key: 0 for key in metrics if key != 'support'}\n",
    "                for metric, value in metrics.items():\n",
    "                    if metric != 'support':\n",
    "                        summed_metrics[category][metric] += value\n",
    "\n",
    "    for cm in cm_list:\n",
    "        for i, category in enumerate(class_names_list):\n",
    "            if category in summed_metrics:  # Ensure category exists in the metrics dictionary\n",
    "                TP = cm[i, i]\n",
    "                TN = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - TP)\n",
    "                FP = cm[:, i].sum() - TP\n",
    "                FN = cm[i, :].sum() - TP\n",
    "                accuracy = (TP + TN) / float(TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
    "                summed_category_accuracies[category] += accuracy\n",
    "\n",
    "    # Calculate average metrics and accuracies\n",
    "    for category in class_names_list:\n",
    "        if category in summed_metrics:\n",
    "            avg_metrics[category] = {metric: summed_metrics[category][metric] / len(rp_list) for metric in ['precision', 'recall', 'f1-score']}\n",
    "    \n",
    "    # Calculate macro and weighted averages\n",
    "    macro_avg = {metric: sum(avg_metrics[cat][metric] for cat in class_names_list) / len(class_names_list) for metric in ['precision', 'recall', 'f1-score']}\n",
    "    weighted_avg = {metric: sum(avg_metrics[cat][metric] * summed_category_accuracies[cat] for cat in class_names_list) / sum(summed_category_accuracies.values()) for metric in ['precision', 'recall', 'f1-score']}\n",
    "    \n",
    "    # Append macro and weighted averages to avg_metrics\n",
    "    avg_metrics['macro avg'] = macro_avg\n",
    "    avg_metrics['weighted avg'] = weighted_avg\n",
    "\n",
    "    avg_accuracy = summed_accuracy / len(rp_list) if len(rp_list) > 0 else 0\n",
    "    avg_category_accuracies = {category: summed_category_accuracies[category] / len(cm_list) for category in class_names_list}\n",
    "\n",
    "    return avg_metrics, avg_category_accuracies, avg_accuracy\n",
    "\n",
    "# Assuming necessary variables (n_folds, valid_rp_list, valid_cm_list, class_names) are defined\n",
    "print('Average classification report of validation set in {:d}-fold'.format(n_folds))\n",
    "avg_metrics, avg_category_accuracies, avg_accuracy = show_rp_list_and_accuracies(valid_rp_list, valid_cm_list, class_names)\n",
    "\n",
    "df_averages = pd.DataFrame(avg_metrics).T\n",
    "df_averages['accuracy'] = pd.Series(avg_category_accuracies)\n",
    "\n",
    "ax = df_averages.plot(kind='bar', figsize=(12, 8), width=0.8, alpha=0.75)\n",
    "ax.set_title('Average Classification Report Metrics for Validation Set')\n",
    "ax.set_ylabel('Average Score')\n",
    "ax.set_xlabel('Category')\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f\"{p.get_height():.2f}\", (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_rp_list_and_accuracies(rp_list, cm_list, class_names):\n",
    "    # Initialize dictionaries for summed and average metrics\n",
    "    summed_metrics, avg_metrics = {}, {}\n",
    "    summed_category_accuracies, avg_category_accuracies = {}, {}\n",
    "    summed_accuracy = 0\n",
    "\n",
    "    # Initialize summed metrics and accuracies\n",
    "    for category in class_names:\n",
    "        summed_metrics[category] = {'precision': 0, 'recall': 0, 'f1-score': 0}\n",
    "        summed_category_accuracies[category] = 0\n",
    "\n",
    "    # Iterate over reports and confusion matrices\n",
    "    for report_index, report in enumerate(rp_list):\n",
    "        for category, metrics in report.items():\n",
    "            # Skip 'accuracy', 'macro avg', and 'weighted avg' categories\n",
    "            if category in ['accuracy', 'macro avg', 'weighted avg']:\n",
    "                if category == 'accuracy':\n",
    "                    summed_accuracy += metrics\n",
    "                continue\n",
    "\n",
    "            # Sum metrics for each category\n",
    "            for metric in ['precision', 'recall', 'f1-score']:\n",
    "                if metric in metrics:\n",
    "                    summed_metrics[category][metric] += metrics[metric]\n",
    "\n",
    "        # Calculate and sum category-specific accuracies\n",
    "        cm = cm_list[report_index]\n",
    "        for i, category in enumerate(class_names):\n",
    "            TP = cm[i, i]\n",
    "            TN = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - TP)\n",
    "            FP = cm[:, i].sum() - TP\n",
    "            FN = cm[i, :].sum() - TP\n",
    "            accuracy = (TP + TN) / float(TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
    "            summed_category_accuracies[category] += accuracy\n",
    "\n",
    "    # Calculate average metrics and accuracies\n",
    "    for category in class_names:\n",
    "        avg_metrics[category] = {metric: value / len(rp_list) for metric, value in summed_metrics[category].items()}\n",
    "        avg_category_accuracies[category] = summed_category_accuracies[category] / len(cm_list)\n",
    "    avg_accuracy = summed_accuracy / len(rp_list)\n",
    "\n",
    "    # Return average metrics and accuracies\n",
    "    return avg_metrics, avg_category_accuracies, avg_accuracy\n",
    "\n",
    "# Use the function for validation set and get the data for plotting\n",
    "avg_metrics, avg_category_accuracies, avg_accuracy = show_rp_list_and_accuracies(valid_rp_list, valid_cm_list, class_names)\n",
    "\n",
    "# Prepare DataFrame for plotting\n",
    "df_averages = pd.DataFrame(avg_metrics).T\n",
    "df_averages['accuracy'] = pd.Series(avg_category_accuracies)\n",
    "\n",
    "# Plotting\n",
    "ax = df_averages.plot(kind='bar', figsize=(12, 8), width=0.8, alpha=0.75)\n",
    "ax.set_title('Average Classification Report Metrics for Validation Set')\n",
    "ax.set_ylabel('Average Score')\n",
    "ax.set_xlabel('Category')\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "# Add value labels to each bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f\"{p.get_height():.2f}\", (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "\n",
    "if len(fi_list) == 0:\n",
    "    exit()\n",
    "    sys.exit()\n",
    "\n",
    "try:\n",
    "    print(clf.importance_type)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "fi_avg = np.mean(fi_list, axis=0)\n",
    "# print(fi_avg)\n",
    "print(fi_avg.argsort()[::-1])\n",
    "if run_from_ipython():\n",
    "    df_feature_importances = pd.DataFrame({'name': features, 'importance': fi_avg})\n",
    "    df_top_10 = df_feature_importances.nlargest(10, columns='importance')\n",
    "    plt.figure()\n",
    "    sns.barplot(x='importance', y='name', data=df_top_10)  # Modified this line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_from_ipython():\n",
    "    plt.figure(figsize=(16, 32))\n",
    "    for i in range(10):\n",
    "        feature_index = df_top_10.index[i]\n",
    "        feature_name = list(df_top_10['name'])[i]\n",
    "        feature_data = X[:, feature_index]\n",
    "\n",
    "        # Check if the lengths match\n",
    "        if len(y_names) != len(feature_data):\n",
    "            print(f\"Length mismatch for feature '{feature_name}': Length of y_names is {len(y_names)}, length of feature data is {len(feature_data)}\")\n",
    "            continue  # Skip this iteration\n",
    "\n",
    "        plt.subplot(5, 2, i+1)\n",
    "        plt.title(feature_name)\n",
    "        ax = sns.boxplot(x=y_names, y=feature_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average classification report of validataion set in K-fold\n",
    "\n",
    "print('Average classification report of validataion set in {:d}-fold'.format(n_folds))\n",
    "show_rp_list(valid_rp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average classification report of validataion set in K-fold\n",
    "\n",
    "print('Average classification report of validataion set in {:d}-fold'.format(n_folds))\n",
    "show_rp_list(valid_rp_list)\n",
    "\n",
    "# 初始化用於存儲每個類別平均精確度、召回率和F1分數的字典\n",
    "averages = {}\n",
    "\n",
    "# 遍歷每個報告\n",
    "for report in valid_rp_list:\n",
    "    # 遍歷報告中的每個類別\n",
    "    for category, metrics in report.items():\n",
    "        # 確保 metrics 是字典類型\n",
    "        if isinstance(metrics, dict):\n",
    "            # 如果類別第一次出現，則初始化\n",
    "            if category not in averages:\n",
    "                averages[category] = {'precision': 0, 'recall': 0, 'f1-score': 0, 'count': 0}\n",
    "            \n",
    "            # 累加該類別的指標值\n",
    "            for metric in ['precision', 'recall', 'f1-score']:\n",
    "                averages[category][metric] += metrics.get(metric, 0)\n",
    "            averages[category]['count'] += 1\n",
    "\n",
    "# 計算平均值\n",
    "for category, metrics in averages.items():\n",
    "    for metric in ['precision', 'recall', 'f1-score']:\n",
    "        metrics[metric] /= metrics['count']\n",
    "\n",
    "# 刪除計數鍵\n",
    "for category in averages:\n",
    "    del averages[category]['count']\n",
    "\n",
    "# 轉換成DataFrame\n",
    "df_averages = pd.DataFrame(averages).T\n",
    "\n",
    "# 繪製柱狀圖並添加數值標籤\n",
    "ax = df_averages.plot(kind='bar', figsize=(12, 8), width=0.8, alpha=0.75)\n",
    "ax.set_title('Average Classification Report Metrics')\n",
    "ax.set_ylabel('Average Score')\n",
    "ax.set_xlabel('Category')\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "# 在每個柱狀圖上添加數值標籤\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f\"{p.get_height():.2f}\", (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    "\n",
    "# 顯示圖表\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_avg = np.mean(fi_list, axis=0)\n",
    "# print(fi_avg)\n",
    "print(fi_avg.argsort()[::-1])\n",
    "if run_from_ipython():\n",
    "    df_feature_importances = pd.DataFrame({'name': features, 'importance': fi_avg})\n",
    "    df_least_10 = df_feature_importances.nsmallest(10, columns='importance')\n",
    "    plt.figure()\n",
    "    sns.barplot(x='importance', y='name', data=df_least_10)  # Corrected this line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_avg = np.mean(fi_list, axis=0)\n",
    "print(fi_avg.argsort()[::-1])\n",
    "if run_from_ipython():\n",
    "    df_feature_importances = pd.DataFrame({'Feature Name': features, 'Importance': fi_avg})\n",
    "    df_least_10 = df_feature_importances.nlargest(len(features), columns='Importance')\n",
    "    plt.figure(figsize=(24, 48))\n",
    "    sns.set(font_scale=2)\n",
    "    sns.barplot(x='Importance', y='Feature Name', data=df_least_10)  # Corrected this line\n",
    "    sns.set(font_scale=1)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('top_10_and_last_10_feature_importance.png')  # Uncomment this line to save the figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "cm_avg = np.mean(valid_cm_list, axis=0)\n",
    "# print(cm_avg)\n",
    "if run_from_ipython():\n",
    "    df_cm = pd.DataFrame(cm_avg, index=class_names, columns=class_names)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    # cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "    cmap = sns.light_palette('black', as_cmap=True)\n",
    "    # cmap = ListedColormap(['white'])\n",
    "    sns.set(font_scale=1.6)\n",
    "    sns.heatmap(df_cm.round(2), annot=True, square=True, cbar=False, cmap=cmap)\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.yticks(rotation=0)\n",
    "    sns.set(font_scale=1)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('confusion_matrix.png')  # Uncomment this line to save the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 计算平均混淆矩阵\n",
    "avg_train_cm = np.mean(train_cm_list, axis=0)\n",
    "avg_valid_cm = np.mean(valid_cm_list, axis=0)\n",
    "\n",
    "# 计算平均AUC分数\n",
    "avg_train_auc = np.mean(train_auc_list)\n",
    "avg_valid_auc = np.mean(valid_auc_list)\n",
    "\n",
    "# 展示平均混淆矩阵\n",
    "print(\"Average Training Confusion Matrix:\")\n",
    "print(avg_train_cm)\n",
    "print(\"\\nAverage Validation Confusion Matrix:\")\n",
    "print(avg_valid_cm)\n",
    "\n",
    "# 展示平均AUC分数\n",
    "print(f\"\\nAverage Train AUC: {avg_train_auc}\")\n",
    "print(f\"Average Valid AUC: {avg_valid_auc}\")\n",
    "\n",
    "# 绘制AUC分数图表\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_auc_list, label='Train AUC', marker='o')\n",
    "plt.plot([avg_train_auc] * len(train_auc_list), 'r--', label='Average Train AUC')\n",
    "plt.plot(valid_auc_list, label='Valid AUC', marker='o')\n",
    "plt.plot([avg_valid_auc] * len(valid_auc_list), 'g--', label='Average Valid AUC')\n",
    "plt.title('AUC Scores per Fold')\n",
    "plt.xlabel('Fold Number')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "\n",
    "# 计算每个类别的FPR和TPR\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = len(class_names)  # 类别的数量\n",
    "\n",
    "# 计算每个类别的ROC曲线和AUC分数\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_valid, y_valid_prob[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# 计算宏观平均ROC曲线和AUC分数\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# 绘制所有类别的ROC曲线\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = cycle(['blue', 'red', 'green', 'cyan', 'magenta'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "# 绘制宏观平均ROC曲线\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "# 绘制对角线\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-class ROC and AUC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
