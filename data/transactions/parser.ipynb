{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from bitcoinrpc.authproxy import AuthServiceProxy, JSONRPCException\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_directory_if_not_exists(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "# 使用正则表达式从文件名中提取索引数字\n",
    "def extract_index(filename):\n",
    "    match = re.search(r'index(\\d+).json', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return -1\n",
    "\n",
    "def save_transaction_data_to_json():\n",
    "\n",
    "    # Setting Bitcoin Core RPC\n",
    "    rpc_user = 'your_rpc_username'\n",
    "    rpc_password = 'your_rpc_password'\n",
    "    rpc_host = 'localhost'\n",
    "    rpc_port = 8332\n",
    "\n",
    "    # Setting init parameters\n",
    "    transaction_count = 0\n",
    "    directory_count = 1\n",
    "    index_data = {}\n",
    "    addresses =[]\n",
    "    coinbase_data = {}\n",
    "    block_height = 1\n",
    "\n",
    "    address_directory = '../address'\n",
    "    # Create address directory if not exists\n",
    "    if not os.path.exists(address_directory):\n",
    "        os.makedirs(address_directory)\n",
    "\n",
    "    # Load index file get block_hash, directory_count, transaction_count\n",
    "    index_directory = '../transactions/index'  # 替换为实际文件夹路径\n",
    "    index_files = os.listdir(index_directory) # 使用os.listdir()获取文件夹中的文件列表并存储在index_files变量中\n",
    "    print(\"index_files: \", index_files)\n",
    "    index_files.sort(key=extract_index) # 对文件列表进行排序\n",
    "\n",
    "    # 确保文件列表非空\n",
    "    if index_files:\n",
    "        # 获取最后一个文件的文件名\n",
    "        last_file = index_files[-1]\n",
    "\n",
    "        # 检查文件是否为JSON文件（可选）\n",
    "        if last_file.endswith('.json'):\n",
    "            json_filepath = os.path.join(index_directory, last_file)\n",
    "\n",
    "            with open(json_filepath, 'r') as json_file:\n",
    "                index_data = json.load(json_file)\n",
    "                block_hash = list(index_data.keys())[-1]\n",
    "                directory_count = int(index_data[block_hash])\n",
    "                transaction_count = len(index_data) % 10000\n",
    "                # 这里您可以处理JSON数据，data变量包含了JSON文件中的内容\n",
    "                print(f\"成功读取最后一个文件: {last_file}\")\n",
    "        else:\n",
    "            print(f\"最后一个文件 '{last_file}' 不是JSON文件\")\n",
    "    else:\n",
    "        print(f\"文件夹 '{index_directory}' 为空\")\n",
    "\n",
    "    print(f\"Last block_hash: {block_hash}\")\n",
    "    print(f\"Last directory_count: {directory_count}\")\n",
    "    print(f\"Last transaction_count: {transaction_count}\")\n",
    "\n",
    "    # Use the block heights for the start and end times\n",
    "    start_block_height = -1\n",
    "    end_block_height = 310000\n",
    "\n",
    "    try:\n",
    "        rpc_connection = AuthServiceProxy(f\"http://{rpc_user}:{rpc_password}@{rpc_host}:{rpc_port}\")\n",
    "        \n",
    "        # Get raw tx data\n",
    "        raw_transaction = rpc_connection.getrawtransaction(block_hash, True)\n",
    "        # Initial start block height\n",
    "        while start_block_height == -1:\n",
    "            if block_height != -1:\n",
    "                # 獲取區塊訊息\n",
    "                block_info = rpc_connection.getblock(raw_transaction[\"blockhash\"])\n",
    "                print(f\"Transaction {block_hash} is in block height {block_height}\")\n",
    "            else:\n",
    "                print(f\"Transaction {block_hash} is not yet confirmed in a block.\")\n",
    "\n",
    "            if \"blockhash\" in raw_transaction:\n",
    "                block_hash = raw_transaction[\"blockhash\"]\n",
    "\n",
    "                # Use block_hash lookup block height\n",
    "                block_info = rpc_connection.getblock(block_hash)\n",
    "                block_height = block_info[\"height\"]\n",
    "                start_block_height = block_height\n",
    "                print(\"start_block_height: \", start_block_height)\n",
    "                print(f\"Transaction with txid '{block_hash}' is in block height {block_height}\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Transaction with txid '{block_hash}' is not yet confirmed in a block.\")\n",
    "        \n",
    "        previous_block_height = start_block_height  # 初始化先前區塊高度為起始高度\n",
    "\n",
    "        for block_height in tqdm(range(start_block_height, end_block_height + 1)):\n",
    "            \n",
    "            # 確認區塊高度的變化\n",
    "            if block_height != previous_block_height:\n",
    "                # 更新先前區塊高度為目前處理的區塊高度\n",
    "                previous_block_height = block_height\n",
    "\n",
    "                block_hash = rpc_connection.getblockhash(block_height)\n",
    "                print(\"block height: \",block_height)\n",
    "                block = rpc_connection.getblock(block_hash)\n",
    "\n",
    "                for tx_id in block['tx']:\n",
    "                    # Check block hash in transaction\n",
    "                    if \"blockhash\" in raw_transaction:\n",
    "                        block_hash = raw_transaction[\"blockhash\"]\n",
    "                        transaction = rpc_connection.getrawtransaction(tx_id, True)\n",
    "                        transaction_hash = transaction['txid']\n",
    "                    else:\n",
    "                        break\n",
    "                    print(\"TXID: \", transaction_hash)\n",
    "                    directory = str(directory_count).zfill(8)\n",
    "                    print(\"File Numbers:\", directory)\n",
    "\n",
    "                    # Add this code to check if the directory exists, and create it if not\n",
    "                    if not os.path.exists(directory):\n",
    "                        os.makedirs(directory)\n",
    "\n",
    "                    # Check transaction and address exist or not\n",
    "                    file_path = os.path.join(directory, f'{transaction_hash}.json')\n",
    "\n",
    "                    # Get output addresses and balancees and output txids\n",
    "                    vout_sz = 0\n",
    "                    addresses = []\n",
    "                    balancees = []\n",
    "                    txrefs = []\n",
    "                    vout_list = transaction['vout']\n",
    "                    for vout in vout_list:\n",
    "                        # Get output balance\n",
    "                        balance = vout['value']\n",
    "\n",
    "                        if balance is not None and balance > 0:  # Check balance > 0\n",
    "                            balancees.append(balance)\n",
    "                            print(\"Balance:\", balance)\n",
    "                        else:\n",
    "                            balancees.append(0)\n",
    "                            print(\"No or empty output balance found for TXID:\", transaction_hash)\n",
    "\n",
    "                        # Get output txid\n",
    "                        txref = transaction_hash\n",
    "                        txrefs.append(txref)\n",
    "\n",
    "                        if 'scriptPubKey' in vout and 'address' in vout['scriptPubKey']:\n",
    "                            # Get output address\n",
    "                            address = vout['scriptPubKey']['address']\n",
    "                            addresses.append(address)\n",
    "\n",
    "                        vout_sz += 1\n",
    "\n",
    "                    # Check if there are output addresses before accessing addresses[0]\n",
    "                    if len(addresses) > 0:\n",
    "                        print(\"Output Addresses:\", addresses)\n",
    "                    else:\n",
    "                        print(\"No output addresses found for TXID:\", transaction_hash)\n",
    "\n",
    "                    print(\"txrefs\", txrefs)\n",
    "                    \n",
    "                    vin_sz = 0\n",
    "                    # Get input txid\n",
    "                    input_tx_id = []\n",
    "                    vin_list = transaction['vin']\n",
    "\n",
    "                    for vin in vin_list:\n",
    "                        vin_sz +=1\n",
    "                        if 'coinbase' not in vin and 'txid' in vin:\n",
    "                            input_tx_id = vin['txid']\n",
    "                            print(\"Input TXID:\", input_tx_id)\n",
    "\n",
    "                    # Get block time\n",
    "                    timestamp = block['time']\n",
    "                    # 使用datetime.utcfromtimestamp將Unix時間戳轉換為UTC日期時間對象\n",
    "                    utc_datetime = datetime.utcfromtimestamp(timestamp)\n",
    "                    # 使用strftime將日期時間對象格式化為'%Y-%m-%dT%H:%M:%S.%fZ'格式\n",
    "                    formatted_date = utc_datetime.strftime('%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "                    # print(formatted_date)\n",
    "\n",
    "                    # Save addresses to a JSON file\n",
    "                    if addresses:\n",
    "                        address_filename = f'{addresses[0]}.json'\n",
    "                        address_directory_path = os.path.join(address_directory, address_filename)\n",
    "                        \n",
    "                        txrefs_list = []  # 用於存儲交易參考的列表\n",
    "\n",
    "                        # Check if the file already exists\n",
    "                        if os.path.exists(address_directory_path):\n",
    "                            # If the file exists, load the existing data\n",
    "                            with open(address_directory_path, 'r') as address_file:\n",
    "                                existing_data = json.load(address_file)\n",
    "                                if 'balance' in existing_data:\n",
    "                                    existing_balance = existing_data['balance']\n",
    "                                    # Update the balance with the new value, if available\n",
    "                                    if balancees and float(balancees[0]) > 0:\n",
    "                                        existing_data['balance'] = float(balancees[0])\n",
    "                                    # Append the new transaction reference to the existing list\n",
    "                                    txref_dict = {\n",
    "                                        'tx_hash': transaction_hash,\n",
    "                                        'tx_input_n': vin_sz,\n",
    "                                        'block_height': block_height,\n",
    "                                        'tx_output_n': vout_sz,\n",
    "                                        'ref_balance': float(balancees[0]),\n",
    "                                        'confirmed': formatted_date\n",
    "                                    }\n",
    "                                    txrefs_list = existing_data.get('txrefs', [])\n",
    "                                    # Ensure the number of txrefs doesn't exceed 5000\n",
    "                                    if len(txrefs_list) < 5000:\n",
    "                                        txrefs_list.append(txref_dict)\n",
    "                                    else:\n",
    "                                        txrefs_list = txrefs_list[:5000]  # 只保留前面 5000 個交易參考\n",
    "                                    existing_data['txrefs'] = txrefs_list\n",
    "\n",
    "                            # Save the updated data back to the file\n",
    "                            with open(address_directory_path, 'w') as address_file:\n",
    "                                json.dump(existing_data, address_file, indent=4, default=str)\n",
    "                        else:\n",
    "                            # If the file does not exist, create a new JSON file with the initial data\n",
    "                            txref_dict = {\n",
    "                                'tx_hash': transaction_hash,\n",
    "                                'tx_input_n': vin_sz,\n",
    "                                'block_height': block_height,\n",
    "                                'tx_output_n': vout_sz,\n",
    "                                'ref_balance': float(balancees[0]),\n",
    "                                'confirmed': formatted_date\n",
    "                            }\n",
    "                            txrefs_list.append(txref_dict)\n",
    "                            with open(address_directory_path, 'w') as address_file:\n",
    "                                json.dump({\n",
    "                                    'balance': float(balancees[0]) if balancees else 0,\n",
    "                                    'txrefs': txrefs_list\n",
    "                                }, address_file, indent=4, default=str)\n",
    "                    else:\n",
    "                        # Handle the case where there are no output addresses\n",
    "                        # You can skip this transaction or provide a default value\n",
    "                        print(\"No output addresses found for TXID:\", transaction_hash)\n",
    "\n",
    "                    # Add this code to check if the directory exists, and create it if not\n",
    "                    if not os.path.exists(directory):\n",
    "                        os.makedirs(directory)\n",
    "\n",
    "                    # Save transaction data to a JSON file\n",
    "                    file_path = os.path.join(directory, f'{transaction_hash}.json')\n",
    "                    with open(file_path, 'w') as file:\n",
    "                        json.dump({\n",
    "                            'tx_hash': transaction_hash,\n",
    "                            'tx_input_n': input_tx_id,\n",
    "                            'vin_sz': vin_sz,\n",
    "                            'tx_output_n': txrefs,\n",
    "                            'vout_sz': vout_sz,\n",
    "                            'block_height': block_height,\n",
    "                            'ref_balance': float(balancees[0]),\n",
    "                            'confirmed': datetime.utcfromtimestamp(block['time']).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                        }, file, indent=4, default=str)\n",
    "\n",
    "                    # Index file name\n",
    "                    index_filename = f'index{directory_count}.json'\n",
    "                    index_filepath = os.path.join(index_directory, index_filename)\n",
    "\n",
    "                    # Update index data\n",
    "                    index_data[transaction_hash] = directory\n",
    "\n",
    "                    with open(index_filepath, 'w') as json_file:\n",
    "                        json.dump(index_data, json_file)\n",
    "\n",
    "                    transaction_count += 1\n",
    "                    if transaction_count % 10000 == 0:\n",
    "                        transaction_count = 0\n",
    "                        index_data = {}\n",
    "                        directory_count += 1\n",
    "\n",
    "                    # Append the \"coinbase\" field to the coinbase_data\n",
    "                    coinbase_data = {\"tx2blk\": index_data}\n",
    "\n",
    "                    # Save coinbase data to coinbase.pkl\n",
    "                    with open('../coinbase.pkl', 'wb') as coinbase_file:\n",
    "                        pickle.dump(coinbase_data, coinbase_file)\n",
    "\n",
    "    except JSONRPCException as e:\n",
    "        print(\"RPC request error:\", e.error)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", str(e))\n",
    "\n",
    "save_transaction_data_to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "directory = '../address'\n",
    "\n",
    "# 遍歷目錄中的所有文件\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "\n",
    "        try:\n",
    "            # 嘗試打開並解析 JSON 文件\n",
    "            with open(file_path, 'r') as file:\n",
    "                json.load(file)\n",
    "        except json.JSONDecodeError:\n",
    "            # 如果解析失敗，刪除該文件\n",
    "            os.remove(file_path)\n",
    "            print(f\"Corrupted file '{filename}' has been deleted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = '../address'\n",
    "file_to_delete = '1H6YbozjMSaARR2AHTSkNyC6S63S4LD2JB.json'\n",
    "file_path = os.path.join(directory, file_to_delete)\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "    print(f\"File '{file_to_delete}' has been deleted successfully.\")\n",
    "else:\n",
    "    print(f\"File '{file_to_delete}' does not exist in the directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 指定 CSV 檔案路徑\n",
    "csv_file_path = '../dataset_allmymerge.csv'\n",
    "\n",
    "# 讀取 CSV 檔案，只選取 'address' 欄位\n",
    "dataset_df = pd.read_csv(csv_file_path, usecols=['address'])\n",
    "\n",
    "# 印出結果\n",
    "addresses_list = dataset_df['address'].tolist()\n",
    "print(addresses_list)\n",
    "\n",
    "# 將 'address' 欄位的資料儲存為新的 CSV 檔案\n",
    "output_csv_path = '../dataset_mymerge_address.csv'\n",
    "dataset_df.to_csv(output_csv_path, index=False, header=['address'])\n",
    "\n",
    "print(f\"資料已儲存至 {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def fix_incomplete_json(file_path):\n",
    "    with open(file_path, 'r+') as file:\n",
    "        try:\n",
    "            content = file.read()\n",
    "            file.seek(0)  # 將檔案指標移回檔案開頭\n",
    "\n",
    "            # 檢查缺少的 '}'、']' 或 ',' 符號\n",
    "            brackets_to_check = [('{', '}'), ('[', ']'), (',', ',')]\n",
    "            for open_bracket, close_bracket in brackets_to_check:\n",
    "                open_count = content.count(open_bracket)\n",
    "                close_count = content.count(close_bracket)\n",
    "\n",
    "                if open_count > close_count:\n",
    "                    diff = open_count - close_count\n",
    "                    content += close_bracket * diff\n",
    "                elif close_count > open_count:\n",
    "                    diff = close_count - open_count\n",
    "                    content = content.replace(close_bracket, '', diff)\n",
    "\n",
    "            # 將修正後的內容重新寫入檔案\n",
    "            file.write(content)\n",
    "            file.truncate()  # 截斷檔案後面多餘的部分（若有）\n",
    "            print(f\"File '{file_path}' has been fixed successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error fixing file '{file_path}': {e}\")\n",
    "\n",
    "directory = '../address'\n",
    "file_to_fix = '1MPxhNkSzeTNTHSZAibMaS8HS1esmUL1ne.json'\n",
    "file_path = os.path.join(directory, file_to_fix)\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    fix_incomplete_json(file_path)\n",
    "else:\n",
    "    print(f\"File '{file_to_fix}' does not exist in the directory.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
