{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dimod\n",
    "from dwave.system import DWaveSampler, EmbeddingComposite\n",
    "from dwave.embedding.chain_strength import uniform_torque_compensation\n",
    "from dwave.embedding.chain_breaks import majority_vote\n",
    "import warnings\n",
    "from scipy.stats import ConstantInputWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelection(object):\n",
    "    def __init__(self, num_features, dependence_coefficients, influence_coefficients):\n",
    "        # Number of features\n",
    "        self.num_features = num_features\n",
    "        self.dependence_coefficients = dependence_coefficients\n",
    "        self.influence_coefficients = influence_coefficients\n",
    "        \n",
    "        # Create binary variables for the features\n",
    "        self.qubo_linear = {i: -influence_coefficients[i] for i in range(num_features)}\n",
    "        self.qubo_quadratic = {(i, j): dependence_coefficients[i][j]\n",
    "                       for i in range(num_features) for j in range(i + 1, num_features)\n",
    "                       if not np.isnan(dependence_coefficients[i][j]) and dependence_coefficients[i][j] != 0}\n",
    "\n",
    "    def compile(self):\n",
    "        # Combine linear and quadratic terms\n",
    "        return dimod.BinaryQuadraticModel(self.qubo_linear, self.qubo_quadratic, 0.0, vartype=dimod.BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化一個集合來儲存所有選中的特徵\n",
    "all_selected_features = set()\n",
    "\n",
    "# 初始化一個字典來儲存每個 class 的 selected_features\n",
    "class_selected_features = {}\n",
    "\n",
    "# Load the CSV file\n",
    "for i in range(0, 6):\n",
    "    # Load the class 0~6 CSV file\n",
    "    file_path = f'../data_p/quantum_data.address_class{i}.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # # 保留前 1% 的資料行數\n",
    "    # num_rows_to_keep = int(len(df) * 0.000001)  # 你可以調整這個比例\n",
    "    # df = df.iloc[:num_rows_to_keep, :]\n",
    "\n",
    "    # 固定保留前 100 行\n",
    "    df = df.iloc[:100, :]  # 固定保留前 100 行\n",
    "\n",
    "    # 偵測資料中是否有空行或空列\n",
    "    if df.isnull().sum().sum() > 0:\n",
    "        print(f\"Class {i}: Detected empty data, handling missing values...\")\n",
    "        # 選擇處理方式，如刪除含有空值的行或列\n",
    "        df = df.dropna(axis=0, how='any')  # 刪除含有空值的行 (也可以選擇 axis=1 刪除列)\n",
    "\n",
    "    # 過濾掉所有常數列\n",
    "    features = df.iloc[:, :-1]\n",
    "    result = df.iloc[:, -1]\n",
    "    features = features.loc[:, (features != features.iloc[0]).any()]  # 只保留變化的列\n",
    "\n",
    "    # 提取列名\n",
    "    columns = features.columns\n",
    "    n_features = features.shape[1]\n",
    "\n",
    "    # Calculate the correlation matrix for features\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=ConstantInputWarning)\n",
    "        feature_correlation = features.corr(method='spearman')\n",
    "\n",
    "    # Calculate the correlation of each feature with the result\n",
    "    result_correlation = features.apply(lambda x: x.corr(result, method='spearman'))\n",
    "\n",
    "    # 在進行量子運算之前，使用過濾後的資料\n",
    "    feature_qubo = FeatureSelection(n_features, feature_correlation.values, result_correlation.values)\n",
    "\n",
    "    # 檢查 `qubo_quadratic` 的長度\n",
    "    expected_length = n_features * (n_features - 1) // 2  # 理論上的二次項長度\n",
    "    if len(feature_qubo.qubo_quadratic) != expected_length:\n",
    "        print(f\"Unexpected quadratic length: {len(feature_qubo.qubo_quadratic)}, expected: {expected_length}\")\n",
    "        continue  # 如果不匹配，跳過這個樣本\n",
    "\n",
    "    bqm = feature_qubo.compile()\n",
    "\n",
    "    # 使用 D-Wave 量子計算機來解 QUBO 問題\n",
    "    qpu_advantage = DWaveSampler(solver={'chip_id': 'Advantage_system6.4'})\n",
    "    sampler = EmbeddingComposite(qpu_advantage)   \n",
    "    response = sampler.sample(bqm, num_reads=1000, chain_strength=uniform_torque_compensation(bqm), chain_break_method=majority_vote, auto_scale=True, reduce_intersample_correlation=True)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"All energies:\", response.record['energy'])\n",
    "\n",
    "    # Find the best sample (modify this as per your criteria)\n",
    "    best_sample = list(response.first.sample.items())\n",
    "\n",
    "    # Identify selected features\n",
    "    selected_features = [int(key) for key, value in best_sample if value == 1]\n",
    "\n",
    "    # Filter the DataFrame to keep only the selected columns\n",
    "    filtered_df = df.iloc[:, selected_features]\n",
    "\n",
    "    # 將本次迭代選中的特徵添加到集合中\n",
    "    all_selected_features.update(selected_features)\n",
    "    \n",
    "    # 將本次迭代選中的特徵儲存到字典中\n",
    "    class_selected_features[i] = selected_features\n",
    "\n",
    "    # Add the index of the last column (class) to the selected features\n",
    "    last_column = df[columns[-1]]\n",
    "    filtered_df = pd.concat([filtered_df, last_column], axis=1)\n",
    "\n",
    "    # Save the filtered DataFrame to a new CSV file\n",
    "    filtered_df.to_csv(f'../data_p/QA_data.address_class{i}.csv', index=False)\n",
    "\n",
    "# Print non-duplicate selected features from all iterations\n",
    "print(\"Combined Selected Features (No Duplicates):\", sorted(all_selected_features))\n",
    "\n",
    "# 也可以打印出每個 class 的 selected_features 來確認\n",
    "for class_num, features in class_selected_features.items():\n",
    "    print(f\"Class {class_num} Selected Features:\", features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 從原始資料根據 all_selected_features 選擇特徵並保存\n",
    "\n",
    "# 讀取原始數據\n",
    "file_path = \"../data_p/data.address.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 將索引轉換為列選擇器\n",
    "# selected_column_indices = list(all_selected_features)\n",
    "\n",
    "# 只選擇 mixer 的特徵\n",
    "selected_column_indices = list(class_selected_features[4])\n",
    "\n",
    "selected_column_indices.append(len(df.columns) - 1)  # 添加最後一列的索引\n",
    "\n",
    "# 使用 .iloc 來選擇指定索引的列\n",
    "filtered_df = df.iloc[:, selected_column_indices]\n",
    "\n",
    "# 確定原始數據集中哪些列不在處理過的數據集中\n",
    "missing_columns = [col for col in df.columns[:-1] if col not in filtered_df.columns]  # 排除最後一列（class）\n",
    "\n",
    "# 為缺失的列創建全為 0 的數據，並添加到處理過的數據集中\n",
    "for col in missing_columns:\n",
    "    filtered_df[col] = 0\n",
    "\n",
    "# 重新排列列的順序以匹配原始數據集\n",
    "filtered_df = filtered_df[df.columns]\n",
    "\n",
    "# 將所有 NaN 值替換為 0\n",
    "filtered_df.fillna(0, inplace=True)\n",
    "\n",
    "# 保存修改後的數據集\n",
    "filtered_df.to_csv(\"../data_p/all_selected_features_QA_data.address.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # 從原始數據根據 all_selected_features 選擇特徵並保存\n",
    "\n",
    "# # 讀取原始數據\n",
    "# file_path = \"../data_p/data.address.csv\"\n",
    "# df = pd.read_csv(file_path)\n",
    "\n",
    "# # 選擇 mixer 的特徵\n",
    "# selected_column_indices = list(class_selected_features[4])\n",
    "# selected_column_indices.append(len(df.columns) - 1)  # 添加最後一列的索引\n",
    "\n",
    "# # 創建一個新的 DataFrame，初始值設為0\n",
    "# zero_df = pd.DataFrame(0, index=df.index, columns=df.columns)\n",
    "\n",
    "# # 保留 selected_column_indices 中的列的原始數據\n",
    "# zero_df.iloc[:, selected_column_indices] = df.iloc[:, selected_column_indices]\n",
    "\n",
    "# # 將所有 NaN 值替換為 0\n",
    "# zero_df.fillna(0, inplace=True)\n",
    "\n",
    "# # 保存修改後的數據集\n",
    "# zero_df.to_csv(\"../data_p/all_selected_features_quantum_qubo_data.address.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 指定 CSV 檔案的路徑\n",
    "file_path = \"../data_p/all_selected_features_QA_data.address.csv\"\n",
    "\n",
    "# 使用 pandas 的 read_csv 函數讀取 CSV 檔案\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 將所有的 NaN 值替換為 0\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# 將 std_balance_btc 列中的數值只取到小數點後 10 位\n",
    "df['std_balance_btc'] = df['std_balance_btc'].round(10)\n",
    "\n",
    "# 保存最後一列\n",
    "last_column = df.iloc[:, -1].copy()\n",
    "\n",
    "# 初始化 StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 選擇除了最後一列之外的數值型列進行標準化\n",
    "numeric_df = df.iloc[:, :-1].select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# 使用 StandardScaler 對選定的數值型數據進行標準化\n",
    "scaled_features = scaler.fit_transform(numeric_df.values)\n",
    "\n",
    "# 將標準化後的數據轉換回 DataFrame\n",
    "scaled_df = pd.DataFrame(scaled_features, index=df.index, columns=numeric_df.columns)\n",
    "\n",
    "# 將最後一列加回 DataFrame\n",
    "scaled_df = pd.concat([scaled_df, last_column], axis=1)\n",
    "\n",
    "# 定義新檔案的路徑\n",
    "new_file_path = \"../data_p/normalization_all_selected_features_QA_data.address.csv\"\n",
    "\n",
    "# 儲存修改後的 DataFrame 到新檔案\n",
    "scaled_df.to_csv(new_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪製特徵相關性熱圖\n",
    "def plot_feature_correlation_heatmap(correlation_matrix, title='Feature Correlation Heatmap'):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# 繪製特徵與類別相關性柱狀圖\n",
    "def plot_feature_class_correlation_bar(correlations, title='Feature-Class Correlation'):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    correlations.plot(kind='bar', color='skyblue')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Correlation with Class')\n",
    "    plt.axhline(y=0, color='black', linestyle='--')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義 class 索引和名稱的對應\n",
    "class_names = {\n",
    "    0: 'Exchange',\n",
    "    1: 'Faucet',\n",
    "    2: 'Gambling',\n",
    "    3: 'Market',\n",
    "    4: 'Mixer',\n",
    "    5: 'Mining Pool'\n",
    "}\n",
    "\n",
    "# Load the CSV file\n",
    "for i in range(0, 6):\n",
    "    # Load the class 0~5 CSV file\n",
    "    file_path = f'../data_p/quantum_data.address_class{i}.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # 移除包含空值的列\n",
    "    df = df.dropna(axis=1)\n",
    "\n",
    "    # Extracting each column as an array\n",
    "    columns = df.columns\n",
    "    features = df[columns[:-1]]  # All columns except the last one\n",
    "    result = df[columns[-1]]    # The last column\n",
    "    n_features = features.shape[1]\n",
    "\n",
    "    # Calculate the correlation matrix for features\n",
    "    feature_correlation = features.corr(method='spearman')\n",
    "    # 繪製特徵相關性熱圖，並使用 class 名稱作為標題\n",
    "    plot_feature_correlation_heatmap(feature_correlation, f'Feature Correlation Heatmap for {class_names[i]}')\n",
    "\n",
    "    # Calculate the correlation of each feature with the result\n",
    "    result_correlation = features.apply(lambda x: x.corr(result, method='spearman'))\n",
    "    # 繪製特徵與結果類別相關性柱狀圖，並使用 class 名稱作為標題\n",
    "    plot_feature_class_correlation_bar(result_correlation, f'Feature-Class Correlation for {class_names[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty DataFrame for merging\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Loop through class0 to class5\n",
    "for i in range(0, 6):\n",
    "    # Read each file\n",
    "    file_path = f'../data_p/quantum_qubo_data.address_class{i}.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Remove rows where the last column (class{i}) has a value of 0\n",
    "    df = df[df[df.columns[-1]] != 0]\n",
    "\n",
    "    # Rename the last column to 'class', and set its value to the current class number for rows with 1\n",
    "    df.rename(columns={df.columns[-1]: 'class'}, inplace=True)\n",
    "    df['class'] = df['class'].apply(lambda x: i if x == 1 else x)\n",
    "\n",
    "    # Add the DataFrame to the merged DataFrame\n",
    "    merged_df = pd.concat([merged_df, df], ignore_index=True)\n",
    "\n",
    "# Fill all NaN values with 0\n",
    "merged_df.fillna(0, inplace=True)\n",
    "\n",
    "# Read the comparison DataFrame\n",
    "data_df = pd.read_csv('../data_p/data.address.csv')\n",
    "\n",
    "# Identify missing columns in the merged DataFrame\n",
    "missing_columns = set(data_df.columns) - set(merged_df.columns)\n",
    "\n",
    "# Add missing columns to the merged DataFrame with default value 0\n",
    "for col in missing_columns:\n",
    "    merged_df[col] = 0\n",
    "\n",
    "# Move the 'class' column to the end\n",
    "class_column = merged_df.pop('class')\n",
    "merged_df['class'] = class_column\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('../data_p/quantum_qubo_data.address.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 讀取原始數據\n",
    "file_path = \"../data_p/data.address.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 將索引轉換為列選擇器\n",
    "# selected_column_indices = list(all_selected_features)\n",
    "\n",
    "# 只選擇 mixer 的特徵\n",
    "selected_column_indices = list(class_selected_features[4])\n",
    "\n",
    "selected_column_indices.append(len(df.columns) - 1)  # 添加最後一列的索引\n",
    "\n",
    "# 使用 .iloc 來選擇指定索引的列\n",
    "filtered_df = df.iloc[:, selected_column_indices]\n",
    "\n",
    "# 確定原始數據集中哪些列不在處理過的數據集中\n",
    "missing_columns = [col for col in df.columns[:-1] if col not in filtered_df.columns]  # 排除最後一列（class）\n",
    "\n",
    "# 為缺失的列創建全為 0 的數據，並添加到處理過的數據集中\n",
    "for col in missing_columns:\n",
    "    filtered_df[col] = 0\n",
    "\n",
    "# 重新排列列的順序以匹配原始數據集\n",
    "filtered_df = filtered_df[df.columns]\n",
    "\n",
    "# 將所有 NaN 值替換為 0\n",
    "filtered_df.fillna(0, inplace=True)\n",
    "\n",
    "# 保存修改後的數據集\n",
    "filtered_df.to_csv(\"../data_p/all_selected_features_quantum_qubo_data.address.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
