{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) 2023 Ming-Fong Sie <seansie07@gmail.com> & Yu-Jing Lin <elvisyjlin@gmail.com>\n",
    "\n",
    "This work is licensed under the Creative Commons Attribution-NonCommercial\n",
    "4.0 International License. To view a copy of this license, visit\n",
    "http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n",
    "Creative Commons, PO Box 1866, Mountain View, CA 94042, USA."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Abbreviations\n",
    "1. cm: confusion matrix\n",
    "2. rp: classification report\n",
    "3. fi: feature importance\n",
    "4. if: important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all used packages\n",
    "\n",
    "import argparse\n",
    "import collections\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import roc_auc_score  # Add this import statement at the beginning\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from learn import get_model, get_params\n",
    "from utils import run_from_ipython, np2df\n",
    "from viz import show_cm_list, show_rp_list\n",
    "\n",
    "if run_from_ipython():\n",
    "    import matplotlib\n",
    "    # %matplotlib inline\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import xgboost\n",
    "    sns.set_context('notebook')  # 'notebook', 'paper', 'talk', 'poster'\n",
    "    # sns.set_style('dark')  # None, 'darkgrid', 'whitegrid', 'dark', 'white', 'ticks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(feature_type='bem', model='xgb', n_folds=10, n_jobs=10, no_cost_sentitive=False, output='./data_p', result='./result', scheme='address')\n"
     ]
    }
   ],
   "source": [
    "# Parse Arguments\n",
    "\n",
    "def parse(args=None):\n",
    "    parser = argparse.ArgumentParser(\n",
    "        prog='Classification',\n",
    "        description='Train and test a machine learning classification method on the extracted features.'\n",
    "    )\n",
    "    parser.add_argument('--n_folds', help='n folds cross validation', type=int, default=10)\n",
    "    parser.add_argument('--model', '-m', help='model/method', type=str,\n",
    "                        choices=['lr', 'p', 'ab', 'rf', 'svm', 'xgb', 'lgb'], default='xgb')\n",
    "    parser.add_argument('--feature_type', '-f',\n",
    "                        help='feature type (\"b\" | \"e\" | \"m\" or \"if4\", \"if5\", \"if10\", \"if13\", \"if20\", \"if64\")',\n",
    "                        type=str, default='bem')\n",
    "    parser.add_argument('--scheme', '-s', help='data scheme', type=str,\n",
    "                        choices=['address', 'entity'], default='address')\n",
    "    parser.add_argument('--n_jobs', '-j', help='number of workers/threads; set -1 to use all processors', type=int, default=10)\n",
    "    parser.add_argument('--no_cost_sentitive', help='disable cost sentitive learning', action='store_true')\n",
    "    parser.add_argument('--output', '-o', help='output path', type=str, default='./data_p')\n",
    "    parser.add_argument('--result', '-r', help='result path', type=str, default='./result')\n",
    "    return parser.parse_args() if args is None else parser.parse_args(args)\n",
    "args = parse([]) if run_from_ipython() else parse()\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Setting\n",
      "===> Model:          xgb\n",
      "===> Feature Types:  bem\n",
      "===> Data Scheme:    address\n",
      "===> Cost Sensitive: True\n",
      "===> N Threads:      10\n"
     ]
    }
   ],
   "source": [
    "# Define the experiment setting\n",
    "\n",
    "n_folds = args.n_folds                       # 10\n",
    "model = args.model                           # 'lr', 'p', 'ab', 'rf', 'svm', 'xgb', 'lgb'\n",
    "feature_type = args.feature_type             # 'b' | 'e' | 'm' or 'if4', 'if5', 'if10', 'if13', 'if20', 'if64'\n",
    "scheme = args.scheme                         # 'address', 'entity'\n",
    "n_jobs = args.n_jobs                         # -1 to use all processors, or any positive integer\n",
    "cost_sensitive = not args.no_cost_sentitive  # True, False\n",
    "output_path = args.output\n",
    "result_path = args.result\n",
    "\n",
    "# Check the experiment setting\n",
    "\n",
    "assert model in ['lr', 'p', 'ab', 'rf', 'svm', 'xgb', 'lgb']\n",
    "assert not feature_type.startswith('if') and len(feature_type) > 0 or \\\n",
    "       feature_type.startswith('if') and feature_type[2:].isdigit()\n",
    "# assert scheme in ['address', 'entity']\n",
    "assert scheme in ['address']\n",
    "\n",
    "# Show the experiment setting\n",
    "\n",
    "print('Experiment Setting')\n",
    "print('===> Model:         ', model)\n",
    "print('===> Feature Types: ', feature_type)\n",
    "print('===> Data Scheme:   ', scheme)\n",
    "print('===> Cost Sensitive:', cost_sensitive)\n",
    "print('===> N Threads:     ', n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        n_tx  total_days  total_spent_btc  total_received_btc  \\\n",
      "0        1.0         1.0         0.011048            0.011048   \n",
      "1        2.0        91.0         0.714653            0.714653   \n",
      "2        1.0         1.0         0.999000            0.999000   \n",
      "3        5.0        30.0        40.642063           40.642063   \n",
      "4        1.0         1.0         0.035000            0.035000   \n",
      "...      ...         ...              ...                 ...   \n",
      "212757   2.0        21.0         1.051200            1.051200   \n",
      "212758   7.0       104.0         0.765639            0.765639   \n",
      "212759   1.0         1.0         0.011394            0.011394   \n",
      "212760   4.0         6.0        10.173900           10.173900   \n",
      "212761   2.0         1.0         0.600000            0.600000   \n",
      "\n",
      "        total_spent_usd  total_received_usd  mean_balance_btc  \\\n",
      "0              2.918842            2.918842          0.011048   \n",
      "1            188.487957          188.487957          0.357326   \n",
      "2            351.280357          351.280357          0.999000   \n",
      "3          14455.199947        14455.199947          8.128413   \n",
      "4             11.786355           11.786355          0.035000   \n",
      "...                 ...                 ...               ...   \n",
      "212757       460.783556          460.783556          0.525600   \n",
      "212758       275.528710          275.528710          0.109377   \n",
      "212759         3.278293            3.278293          0.011394   \n",
      "212760      3998.545578         3998.545578          2.543475   \n",
      "212761       161.417999          161.417999          0.300000   \n",
      "\n",
      "        std_balance_btc  mean_balance_usd  std_balance_usd  ...  \\\n",
      "0              0.000000          2.918842     0.000000e+00  ...   \n",
      "1              0.058742         94.243979     1.940964e+03  ...   \n",
      "2              0.000000        351.280357     0.000000e+00  ...   \n",
      "3             14.212943       2891.039989     2.052068e+06  ...   \n",
      "4              0.000000         11.786355     0.000000e+00  ...   \n",
      "...                 ...               ...              ...  ...   \n",
      "212757         0.224964        230.391778     4.492990e+04  ...   \n",
      "212758         0.010206         39.361244     1.668821e+03  ...   \n",
      "212759         0.000000          3.278293     0.000000e+00  ...   \n",
      "212760         6.792764        999.636394     1.037761e+06  ...   \n",
      "212761         0.000000         80.709000     0.000000e+00  ...   \n",
      "\n",
      "        dist_spend_4th_moment  dist_receive_1st_moment  \\\n",
      "0                         NaN                 0.000000   \n",
      "1                    1.000000              7057.500000   \n",
      "2                         NaN                 0.000000   \n",
      "3                    2.550663              1743.600000   \n",
      "4                         NaN                 0.000000   \n",
      "...                       ...                      ...   \n",
      "212757               1.000000              1743.500000   \n",
      "212758               1.086165              8864.428571   \n",
      "212759                    NaN                 0.000000   \n",
      "212760               1.347323               367.500000   \n",
      "212761               1.000000                 1.500000   \n",
      "\n",
      "        dist_receive_2nd_moment  dist_receive_3rd_moment  \\\n",
      "0                  0.000000e+00                      NaN   \n",
      "1                  4.980831e+07                 0.000000   \n",
      "2                  0.000000e+00                      NaN   \n",
      "3                  2.483541e+06                 0.880978   \n",
      "4                  0.000000e+00                      NaN   \n",
      "...                         ...                      ...   \n",
      "212757             3.039792e+06                 0.000000   \n",
      "212758             5.889178e+07                -0.284748   \n",
      "212759             0.000000e+00                      NaN   \n",
      "212760             1.268032e+05                 0.249329   \n",
      "212761             2.250000e+00                 0.000000   \n",
      "\n",
      "        dist_receive_4th_moment  dist_payback_1st_moment  \\\n",
      "0                           NaN                 0.000000   \n",
      "1                      1.000000              7057.500000   \n",
      "2                           NaN                 0.000000   \n",
      "3                      2.550663              1743.600000   \n",
      "4                           NaN                 0.000000   \n",
      "...                         ...                      ...   \n",
      "212757                 1.000000              1743.500000   \n",
      "212758                 1.086165              8864.428571   \n",
      "212759                      NaN                 0.000000   \n",
      "212760                 1.347323               367.500000   \n",
      "212761                 1.000000                 1.500000   \n",
      "\n",
      "        dist_payback_2nd_moment  dist_payback_3rd_moment  \\\n",
      "0                  0.000000e+00                      NaN   \n",
      "1                  4.980831e+07                 0.000000   \n",
      "2                  0.000000e+00                      NaN   \n",
      "3                  2.483541e+06                 0.880978   \n",
      "4                  0.000000e+00                      NaN   \n",
      "...                         ...                      ...   \n",
      "212757             3.039792e+06                 0.000000   \n",
      "212758             5.889178e+07                -0.284748   \n",
      "212759             0.000000e+00                      NaN   \n",
      "212760             1.268032e+05                 0.249329   \n",
      "212761             2.250000e+00                 0.000000   \n",
      "\n",
      "        dist_payback_4th_moment  class  \n",
      "0                           NaN      0  \n",
      "1                      1.000000      3  \n",
      "2                           NaN      4  \n",
      "3                      2.550663      5  \n",
      "4                           NaN      3  \n",
      "...                         ...    ...  \n",
      "212757                 1.000000      3  \n",
      "212758                 1.086165      3  \n",
      "212759                      NaN      5  \n",
      "212760                 1.347323      5  \n",
      "212761                 1.000000      2  \n",
      "\n",
      "[212762 rows x 69 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load transaction history summarization data\n",
    "\n",
    "data_file = 'data.{}.csv'.format(scheme)\n",
    "# data_file = 'quantum_qubo_data.{}.csv'.format(scheme)\n",
    "# data_file = 'all_selected_features_quantum_qubo_data.{}.csv'.format(scheme)\n",
    "data = pd.read_csv(os.path.join(output_path, data_file))\n",
    "print (data)\n",
    "if run_from_ipython():\n",
    "    data.head(4)\n",
    "else:\n",
    "    print(data.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f_tx', 'f_received', 'f_coinbase', 'f_spent_digits_-3', 'f_spent_digits_-2', 'f_spent_digits_-1', 'f_spent_digits_0', 'f_spent_digits_1', 'f_spent_digits_2', 'f_spent_digits_3', 'f_spent_digits_4', 'f_spent_digits_5', 'f_spent_digits_6', 'f_received_digits_-3', 'f_received_digits_-2', 'f_received_digits_-1', 'f_received_digits_0', 'f_received_digits_1', 'f_received_digits_2', 'f_received_digits_3', 'f_received_digits_4', 'f_received_digits_5', 'f_received_digits_6', 'r_payback', 'n_inputs_in_spent', 'n_outputs_in_spent', 'n_tx', 'total_days', 'n_spent', 'n_received', 'n_coinbase', 'n_payback', 'total_spent_btc', 'total_received_btc', 'total_spent_usd', 'total_received_usd', 'mean_balance_btc', 'std_balance_btc', 'mean_balance_usd', 'std_balance_usd', 'interval_1st_moment', 'interval_2nd_moment', 'interval_3rd_moment', 'interval_4th_moment', 'dist_total_1st_moment', 'dist_total_2nd_moment', 'dist_total_3rd_moment', 'dist_total_4th_moment', 'dist_coinbase_1st_moment', 'dist_coinbase_2nd_moment', 'dist_coinbase_3rd_moment', 'dist_coinbase_4th_moment', 'dist_spend_1st_moment', 'dist_spend_2nd_moment', 'dist_spend_3rd_moment', 'dist_spend_4th_moment', 'dist_receive_1st_moment', 'dist_receive_2nd_moment', 'dist_receive_3rd_moment', 'dist_receive_4th_moment', 'dist_payback_1st_moment', 'dist_payback_2nd_moment', 'dist_payback_3rd_moment', 'dist_payback_4th_moment']\n",
      "bem\n",
      "[[1.00000000e+00 1.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "             nan            nan]\n",
      " [2.19780220e-02 1.00000000e+00 0.00000000e+00 ... 4.98083062e+07\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+00 1.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "             nan            nan]\n",
      " ...\n",
      " [1.00000000e+00 1.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "             nan            nan]\n",
      " [6.66666667e-01 1.00000000e+00 0.00000000e+00 ... 1.26803250e+05\n",
      "  2.49329116e-01 1.34732277e+00]\n",
      " [2.00000000e+00 1.00000000e+00 0.00000000e+00 ... 2.25000000e+00\n",
      "  0.00000000e+00 1.00000000e+00]]\n",
      "[0 3 4 ... 5 5 2]\n",
      "['Exchange' 'Faucet' 'Gambling' 'Market' 'Mixer' 'Pool']\n",
      "212762 212762 64\n"
     ]
    }
   ],
   "source": [
    "# Define 3 types of features (basic statistics, extra statistics, and moments)\n",
    "\n",
    "basic = [\n",
    "    'f_tx', 'f_received', 'f_coinbase',\n",
    "    'f_spent_digits_-3', 'f_spent_digits_-2', 'f_spent_digits_-1', 'f_spent_digits_0',\n",
    "    'f_spent_digits_1', 'f_spent_digits_2', 'f_spent_digits_3', 'f_spent_digits_4',\n",
    "    'f_spent_digits_5', 'f_spent_digits_6', 'f_received_digits_-3', 'f_received_digits_-2',\n",
    "    'f_received_digits_-1', 'f_received_digits_0', 'f_received_digits_1', 'f_received_digits_2',\n",
    "    'f_received_digits_3', 'f_received_digits_4', 'f_received_digits_5', 'f_received_digits_6',\n",
    "    'r_payback', 'n_inputs_in_spent', 'n_outputs_in_spent'\n",
    "]\n",
    "extra = [\n",
    "    'n_tx', 'total_days', 'n_spent', 'n_received', 'n_coinbase', 'n_payback',\n",
    "    'total_spent_btc', 'total_received_btc',\n",
    "    'total_spent_usd', 'total_received_usd',\n",
    "    'mean_balance_btc', 'std_balance_btc',\n",
    "    'mean_balance_usd', 'std_balance_usd'\n",
    "]\n",
    "moments = [\n",
    "    'interval_1st_moment', 'interval_2nd_moment', 'interval_3rd_moment', 'interval_4th_moment',\n",
    "    'dist_total_1st_moment', 'dist_total_2nd_moment', 'dist_total_3rd_moment', 'dist_total_4th_moment',\n",
    "    'dist_coinbase_1st_moment', 'dist_coinbase_2nd_moment', 'dist_coinbase_3rd_moment', 'dist_coinbase_4th_moment',\n",
    "    'dist_spend_1st_moment', 'dist_spend_2nd_moment', 'dist_spend_3rd_moment', 'dist_spend_4th_moment',\n",
    "    'dist_receive_1st_moment', 'dist_receive_2nd_moment', 'dist_receive_3rd_moment', 'dist_receive_4th_moment',\n",
    "    'dist_payback_1st_moment', 'dist_payback_2nd_moment', 'dist_payback_3rd_moment', 'dist_payback_4th_moment'\n",
    "]\n",
    "\n",
    "features = []\n",
    "if not feature_type.startswith('if') and len(feature_type) > 0:\n",
    "    if 'b' in feature_type:\n",
    "        features += basic\n",
    "    if 'e' in feature_type:\n",
    "        features += extra\n",
    "    if 'm' in feature_type:\n",
    "        features += moments\n",
    "elif feature_type.startswith('if') and feature_type[2:].isdigit():\n",
    "    \"\"\"\n",
    "    Important features from LightGBM with BEM\n",
    "    [ 0 25 24 29 40 37 27 23 56 36  1 28 26 57 32 38 44 45 33 18 39 60 53 35\n",
    "     34 52 41 17 14 15 16 19 42  5  6 47  7 46  2 54  4 43  8 59 58 55  9 13\n",
    "     61 48  3 31 10 62 20 21 63 30 49 11 51 50 22 12]\n",
    "    \"\"\"\n",
    "    all_features = basic + extra + moments\n",
    "    if_indices = [\n",
    "        0, 25, 24, 29, 40, 37, 27, 23, 56, 36,\n",
    "        1, 28, 26, 57, 32, 38, 44, 45, 33, 18,\n",
    "        39, 60, 53, 35, 34, 52, 41, 17, 14, 15,\n",
    "        16, 19, 42, 5, 6, 47, 7, 46, 2, 54,\n",
    "        4, 43, 8, 59, 58, 55, 9, 13, 61, 48,\n",
    "        3, 31, 10, 62, 20, 21, 63, 30, 49, 11,\n",
    "        51, 50, 22, 12\n",
    "    ]\n",
    "    if_features = [all_features[i] for i in if_indices]\n",
    "    n_if = int(feature_type[2:])\n",
    "    features = if_features[:n_if]\n",
    "else:\n",
    "    raise Exception('Invalid feature types: {:s}'.format(feature_type))\n",
    "\n",
    "invalid_features = [feature for feature in features if feature not in data.columns]\n",
    "assert len(invalid_features) == 0, 'Invalid features: ' + ', '.join(invalid_features)\n",
    "\n",
    "X = data.get(features).values\n",
    "y = data['class'].values\n",
    "print (features)\n",
    "print (feature_type)\n",
    "print (X)\n",
    "print (y)\n",
    "\n",
    "class2label = json.loads(open(os.path.join(output_path, 'class2label.json'), 'r').read())\n",
    "label2class = json.loads(open(os.path.join(output_path, 'label2class.json'), 'r').read())\n",
    "class_names = np.array([label2class[i] for i in range(6)])\n",
    "print (class_names)\n",
    "y_names = class_names\n",
    "# y_names = class_names[y]\n",
    "# y_names = np.array(class_names)[y.astype(int)]\n",
    "\n",
    "print(len(X), len(y), len(features))\n",
    "\n",
    "os.makedirs(result_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Exchange': 0, 'Faucet': 1, 'Gambling': 2, 'Market': 3, 'Mixer': 4, 'Pool': 5}\n",
      "          0    1    2    3    4    5    6    7    8    9   ...        54  \\\n",
      "0   1.000000  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       NaN   \n",
      "3   0.021978  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
      "4   1.000000  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       NaN   \n",
      "5   0.166667  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.880978   \n",
      "3   1.000000  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       NaN   \n",
      "..       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
      "3   0.095238  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
      "3   0.067308  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.284748   \n",
      "5   1.000000  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...       NaN   \n",
      "5   0.666667  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.249329   \n",
      "2   2.000000  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.000000   \n",
      "\n",
      "          55           56            57        58        59           60  \\\n",
      "0        NaN     0.000000  0.000000e+00       NaN       NaN     0.000000   \n",
      "3   1.000000  7057.500000  4.980831e+07  0.000000  1.000000  7057.500000   \n",
      "4        NaN     0.000000  0.000000e+00       NaN       NaN     0.000000   \n",
      "5   2.550663  1743.600000  2.483541e+06  0.880978  2.550663  1743.600000   \n",
      "3        NaN     0.000000  0.000000e+00       NaN       NaN     0.000000   \n",
      "..       ...          ...           ...       ...       ...          ...   \n",
      "3   1.000000  1743.500000  3.039792e+06  0.000000  1.000000  1743.500000   \n",
      "3   1.086165  8864.428571  5.889178e+07 -0.284748  1.086165  8864.428571   \n",
      "5        NaN     0.000000  0.000000e+00       NaN       NaN     0.000000   \n",
      "5   1.347323   367.500000  1.268032e+05  0.249329  1.347323   367.500000   \n",
      "2   1.000000     1.500000  2.250000e+00  0.000000  1.000000     1.500000   \n",
      "\n",
      "              61        62        63  \n",
      "0   0.000000e+00       NaN       NaN  \n",
      "3   4.980831e+07  0.000000  1.000000  \n",
      "4   0.000000e+00       NaN       NaN  \n",
      "5   2.483541e+06  0.880978  2.550663  \n",
      "3   0.000000e+00       NaN       NaN  \n",
      "..           ...       ...       ...  \n",
      "3   3.039792e+06  0.000000  1.000000  \n",
      "3   5.889178e+07 -0.284748  1.086165  \n",
      "5   0.000000e+00       NaN       NaN  \n",
      "5   1.268032e+05  0.249329  1.347323  \n",
      "2   2.250000e+00  0.000000  1.000000  \n",
      "\n",
      "[212762 rows x 64 columns]\n",
      "Counter({3: 71099, 0: 56532, 5: 32449, 2: 26707, 4: 16682, 1: 9293})\n"
     ]
    }
   ],
   "source": [
    "def data_distribution(df):\n",
    "    if run_from_ipython():\n",
    "        plt.figure()\n",
    "        sns.countplot(df.index)\n",
    "    cnt = collections.Counter(df.index)\n",
    "    print(cnt)\n",
    "    return np.array([cnt[i] for i in range(len(cnt))])\n",
    "\n",
    "print(class2label)\n",
    "data_dict = np2df(X, y)\n",
    "print(data_dict)\n",
    "y_count = data_distribution(data_dict)\n",
    "# y_count = data_distribution(np2df(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training procedure\n",
    "\n",
    "train_cm_list = []\n",
    "train_rp_list = []\n",
    "valid_cm_list = []\n",
    "valid_rp_list = []\n",
    "fi_list = []\n",
    "\n",
    "# Add these lists to store AUC scores\n",
    "train_auc_list = []\n",
    "valid_auc_list = []\n",
    "\n",
    "# Model parameters\n",
    "clf_params = get_params(model)\n",
    "if model not in ['ab', 'svm']:\n",
    "    clf_params['n_jobs'] = n_jobs\n",
    "print('Hyper-parameters:')\n",
    "print(clf_params)\n",
    "\n",
    "# Declare K-Fold\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "# Normalize data\n",
    "# Note that decision tree sbased algorithms need no data normalization\n",
    "if model in ['lr', 'p', 'svm']:\n",
    "    print('Normalizing data...')\n",
    "    X = np.nan_to_num(X / np.abs(X).max(axis=0))\n",
    "\n",
    "# Start cross validation\n",
    "for train_idx, valid_idx in tqdm(skf.split(X, y)):\n",
    "    # print(train_idx[:100], valid_idx[:10])\n",
    "    \n",
    "    # Retrieve splitted training set and validating set\n",
    "    X_train, X_valid = X[train_idx], X[valid_idx]\n",
    "    y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "    \n",
    "    # Calculate sample weight (whether to apply cost sensitive learning)\n",
    "    sample_weight = np.ones((len(y_train), ), dtype='float64')\n",
    "    if cost_sensitive:\n",
    "        sample_weight = class_weight.compute_sample_weight('balanced', y_train)\n",
    "    \n",
    "    # Declare the classifier and train it on the training set\n",
    "    clf = get_model(model, clf_params)\n",
    "    # clf.fit(X_train, y_train)\n",
    "    clf.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "    \n",
    "    # Evaluate on the training set\n",
    "    y_pred = clf.predict(X_train)\n",
    "    cm = confusion_matrix(y_train, y_pred)\n",
    "    cm = cm / cm.sum(axis=1, keepdims=True)\n",
    "    train_cm_list.append(cm)\n",
    "    rp = classification_report(y_train, y_pred, target_names=class_names, output_dict=True)\n",
    "    train_rp_list.append(rp)\n",
    "    \n",
    "    # Evaluate on the validating set\n",
    "    y_pred = clf.predict(X_valid)\n",
    "    cm = confusion_matrix(y_valid, y_pred)\n",
    "    cm = cm / cm.sum(axis=1, keepdims=True)\n",
    "    valid_cm_list.append(cm)\n",
    "    rp = classification_report(y_valid, y_pred, target_names=class_names, output_dict=True)\n",
    "    valid_rp_list.append(rp)\n",
    "    \n",
    "    # Get the feature importances according to the trained model\n",
    "    if model in ['rf', 'xgb', 'lgb']:\n",
    "        if 'booster' in clf_params and clf_params['booster'] == 'dart':\n",
    "            pass\n",
    "        else:\n",
    "            fi = clf.feature_importances_\n",
    "            fi_list.append(fi)\n",
    "            \n",
    "    # Calculate AUC for the training set\n",
    "    y_train_prob = clf.predict_proba(X_train)\n",
    "    train_auc = roc_auc_score(y_train, y_train_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "    train_auc_list.append(train_auc)\n",
    "\n",
    "    # Calculate AUC for the validation set\n",
    "    y_valid_prob = clf.predict_proba(X_valid)\n",
    "    valid_auc = roc_auc_score(y_valid, y_valid_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "    valid_auc_list.append(valid_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training results\n",
    "\n",
    "experiment_name = os.path.join(result_path, '{}.{}.{}'.format(model, feature_type, scheme))\n",
    "if not cost_sensitive:\n",
    "    experiment_name += '.no_cs'\n",
    "results = {\n",
    "    'train_cm_list': train_cm_list,\n",
    "    'valid_cm_list': valid_cm_list,\n",
    "    'train_rp_list': train_rp_list,\n",
    "    'valid_rp_list': valid_rp_list,\n",
    "    'fi_list': fi_list\n",
    "}\n",
    "pickle.dump(results, open(experiment_name + '.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average confusion matrix of training set in K-fold\n",
    "\n",
    "print('Average confusion matrix of training set in {:d}-fold'.format(n_folds))\n",
    "show_cm_list(train_cm_list, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_rp_list(rp_list):\n",
    "    # Initialize a dictionary to hold the summed metrics\n",
    "    summed_metrics = {}\n",
    "    \n",
    "    # Iterate over each report in the list\n",
    "    for report in rp_list:\n",
    "        for category, metrics in report.items():\n",
    "            # Check if metrics is a dictionary\n",
    "            if isinstance(metrics, dict):\n",
    "                if category not in summed_metrics:\n",
    "                    summed_metrics[category] = {key: 0 for key in metrics if key != 'support'}\n",
    "                for metric, value in metrics.items():\n",
    "                    if metric != 'support':\n",
    "                        summed_metrics[category][metric] += value\n",
    "            else:\n",
    "                # Handle the case where metrics is a float (like 'accuracy')\n",
    "                if category not in summed_metrics:\n",
    "                    summed_metrics[category] = 0\n",
    "                summed_metrics[category] += metrics\n",
    "\n",
    "    # Now calculate the average\n",
    "    avg_metrics = {}\n",
    "    for category, metrics in summed_metrics.items():\n",
    "        if isinstance(metrics, dict):\n",
    "            avg_metrics[category] = {metric: value / len(rp_list) for metric, value in metrics.items()}\n",
    "        else:\n",
    "            # Average for float values\n",
    "            avg_metrics[category] = metrics / len(rp_list)\n",
    "\n",
    "    # Print the average metrics\n",
    "    for category, metrics in avg_metrics.items():\n",
    "        print(f\"Category: {category}\")\n",
    "        if isinstance(metrics, dict):\n",
    "            for metric, value in metrics.items():\n",
    "                print(f\"  {metric}: {value}\")\n",
    "        else:\n",
    "            print(f\"  Value: {metrics}\")\n",
    "        print()\n",
    "\n",
    "# Average classification report of training set in K-fold\n",
    "\n",
    "print('Average classification report of training set in {:d}-fold'.format(n_folds))\n",
    "show_rp_list(train_rp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average confusion matrix of validataion set in K-fold\n",
    "\n",
    "print('Average confusion matrix of validataion set in {:d}-fold'.format(n_folds))\n",
    "show_cm_list(valid_cm_list, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average classification report of validataion set in K-fold\n",
    "\n",
    "print('Average classification report of validataion set in {:d}-fold'.format(n_folds))\n",
    "show_rp_list(valid_rp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "\n",
    "if len(fi_list) == 0:\n",
    "    exit()\n",
    "    sys.exit()\n",
    "\n",
    "try:\n",
    "    print(clf.importance_type)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "fi_avg = np.mean(fi_list, axis=0)\n",
    "# print(fi_avg)\n",
    "print(fi_avg.argsort()[::-1])\n",
    "if run_from_ipython():\n",
    "    df_feature_importances = pd.DataFrame({'name': features, 'importance': fi_avg})\n",
    "    df_top_10 = df_feature_importances.nlargest(10, columns='importance')\n",
    "    plt.figure()\n",
    "    sns.barplot(x='importance', y='name', data=df_top_10)  # Modified this line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_from_ipython():\n",
    "    plt.figure(figsize=(16, 32))\n",
    "    for i in range(10):\n",
    "        feature_index = df_top_10.index[i]\n",
    "        feature_name = list(df_top_10['name'])[i]\n",
    "        feature_data = X[:, feature_index]\n",
    "\n",
    "        # Check if the lengths match\n",
    "        if len(y_names) != len(feature_data):\n",
    "            print(f\"Length mismatch for feature '{feature_name}': Length of y_names is {len(y_names)}, length of feature data is {len(feature_data)}\")\n",
    "            continue  # Skip this iteration\n",
    "\n",
    "        plt.subplot(5, 2, i+1)\n",
    "        plt.title(feature_name)\n",
    "        ax = sns.boxplot(x=y_names, y=feature_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_avg = np.mean(fi_list, axis=0)\n",
    "# print(fi_avg)\n",
    "print(fi_avg.argsort()[::-1])\n",
    "if run_from_ipython():\n",
    "    df_feature_importances = pd.DataFrame({'name': features, 'importance': fi_avg})\n",
    "    df_least_10 = df_feature_importances.nsmallest(10, columns='importance')\n",
    "    plt.figure()\n",
    "    sns.barplot(x='importance', y='name', data=df_least_10)  # Corrected this line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi_avg = np.mean(fi_list, axis=0)\n",
    "print(fi_avg.argsort()[::-1])\n",
    "if run_from_ipython():\n",
    "    df_feature_importances = pd.DataFrame({'Feature Name': features, 'Importance': fi_avg})\n",
    "    df_least_10 = df_feature_importances.nlargest(len(features), columns='Importance')\n",
    "    plt.figure(figsize=(24, 48))\n",
    "    sns.set(font_scale=2)\n",
    "    sns.barplot(x='Importance', y='Feature Name', data=df_least_10)  # Corrected this line\n",
    "    sns.set(font_scale=1)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('top_10_and_last_10_feature_importance.png')  # Uncomment this line to save the figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "cm_avg = np.mean(valid_cm_list, axis=0)\n",
    "# print(cm_avg)\n",
    "if run_from_ipython():\n",
    "    df_cm = pd.DataFrame(cm_avg, index=class_names, columns=class_names)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    # cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "    cmap = sns.light_palette('black', as_cmap=True)\n",
    "    # cmap = ListedColormap(['white'])\n",
    "    sns.set(font_scale=1.6)\n",
    "    sns.heatmap(df_cm.round(2), annot=True, square=True, cbar=False, cmap=cmap)\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.yticks(rotation=0)\n",
    "    sns.set(font_scale=1)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig('confusion_matrix.png')  # Uncomment this line to save the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 计算平均混淆矩阵\n",
    "avg_train_cm = np.mean(train_cm_list, axis=0)\n",
    "avg_valid_cm = np.mean(valid_cm_list, axis=0)\n",
    "\n",
    "# 计算平均AUC分数\n",
    "avg_train_auc = np.mean(train_auc_list)\n",
    "avg_valid_auc = np.mean(valid_auc_list)\n",
    "\n",
    "# 展示平均混淆矩阵\n",
    "print(\"Average Training Confusion Matrix:\")\n",
    "print(avg_train_cm)\n",
    "print(\"\\nAverage Validation Confusion Matrix:\")\n",
    "print(avg_valid_cm)\n",
    "\n",
    "# 展示平均AUC分数\n",
    "print(f\"\\nAverage Train AUC: {avg_train_auc}\")\n",
    "print(f\"Average Valid AUC: {avg_valid_auc}\")\n",
    "\n",
    "# 绘制AUC分数图表\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_auc_list, label='Train AUC', marker='o')\n",
    "plt.plot([avg_train_auc] * len(train_auc_list), 'r--', label='Average Train AUC')\n",
    "plt.plot(valid_auc_list, label='Valid AUC', marker='o')\n",
    "plt.plot([avg_valid_auc] * len(valid_auc_list), 'g--', label='Average Valid AUC')\n",
    "plt.title('AUC Scores per Fold')\n",
    "plt.xlabel('Fold Number')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "\n",
    "# 计算每个类别的FPR和TPR\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "n_classes = len(class_names)  # 类别的数量\n",
    "\n",
    "# 计算每个类别的ROC曲线和AUC分数\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_valid, y_valid_prob[:, i], pos_label=i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# 计算宏观平均ROC曲线和AUC分数\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# 绘制所有类别的ROC曲线\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = cycle(['blue', 'red', 'green', 'cyan', 'magenta'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "# 绘制宏观平均ROC曲线\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "# 绘制对角线\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-class ROC and AUC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
